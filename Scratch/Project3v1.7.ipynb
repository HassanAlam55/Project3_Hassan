{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 to use ML to predict stock prices\n",
    "1. read SP 500\n",
    "2. Find Corrleation between price\n",
    "3. Experiment to see if corrleated on uncorrlated prices have ino\n",
    "4. PCA on prices\n",
    "5. LSTM - Multip Period multi task\n",
    "6. IBM Info\n",
    "7. Other ML Methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "Section 1. Read SP 500\n",
    "    - need to do real time from Alpaca\n",
    "Section 2. Correlation experiements\n",
    "    - drop corrleated elements?\n",
    "Section 3 Set up LSTM\n",
    "Section 4 Read News API\n",
    "Section 5 IBM Tone Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Notes\n",
    "Read SP 500 - v1.2<br>\n",
    "Correllation Experiments:<br>\n",
    "    fraction change and % change have same correlation matrix<br>\n",
    "    log fraction change almost same corrleation matrix as %change<br>\n",
    "V 1.2:<br>\n",
    "    - got lstm working<br>\n",
    "    - inverse scaling not working<br>\n",
    "        - seems to be that information of scaling is not preserved when passing through function or return the scalers through funcitons<br>\n",
    "v 1.4: <br>\n",
    "    - include entire lstm code in one module to see how it modularized Section 3.4<br>\n",
    "    - v1.4.1fixed by changed number of dropped columns<br>\n",
    "    - need to make it into a function<br>\n",
    "v 1.5: <br>\n",
    "    - add newsfeed.<br>\n",
    "    - news feed donedone can only do one month for free <br>\n",
    "    - now to merge news with data\n",
    "v 1.6: <br>\n",
    "    - added IBM Tone.\n",
    "    \n",
    "V 1.7 Integrate the systems..\n",
    "    \n",
    "    \n",
    "To do:<br>\n",
    "    - make LSTM a function call.<br>\n",
    "    - figure out why LSTM dropping some columns<br>\n",
    "    - Connect to Alpaca live<br>\n",
    "    - need to get news api for more than one month with paid input\n",
    "\n",
    "New order of moduels\n",
    "1. Read Stock prices\n",
    "2. read news areticles\n",
    "3. Code sentiment of articles\n",
    "4. Join stock prices and sentiment\n",
    "5. Feed into LSTM model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\Hassan\\Anaconda3\\envs\\pyvizenv\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import alpaca_trade_api as tradeapi\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from dotenv import load_dotenv\n",
    "from ibm_watson import ToneAnalyzerV3\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import concatenate\n",
    "from numpy import concatenate\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas.io.json import json_normalize\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "import json\n",
    "# deoes not work use next cell\n",
    "# from pandas import json_normalize\n",
    "from ibm_watson import ToneAnalyzerV3\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from pandas.io.json import json_normalize\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "load_dotenv('ibm-credentials.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dotenv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-934607ef0955>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mload_dotenv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test1.env'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'load_dotenv' is not defined"
     ]
    }
   ],
   "source": [
    "load_dotenv('test1.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sectioin 1. Read SP 500\n",
    "In this case from stored files. Do for real time with Alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02 05:00:00+00:00</th>\n",
       "      <td>85.95</td>\n",
       "      <td>29.09</td>\n",
       "      <td>159.40</td>\n",
       "      <td>300.58</td>\n",
       "      <td>89.57</td>\n",
       "      <td>85.09</td>\n",
       "      <td>168.81</td>\n",
       "      <td>86.94</td>\n",
       "      <td>210.15</td>\n",
       "      <td>334.48</td>\n",
       "      <td>...</td>\n",
       "      <td>62.38</td>\n",
       "      <td>101.69</td>\n",
       "      <td>70.900</td>\n",
       "      <td>56.94</td>\n",
       "      <td>79.87</td>\n",
       "      <td>102.18</td>\n",
       "      <td>149.20</td>\n",
       "      <td>259.14</td>\n",
       "      <td>52.44</td>\n",
       "      <td>134.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03 05:00:00+00:00</th>\n",
       "      <td>84.53</td>\n",
       "      <td>27.65</td>\n",
       "      <td>159.48</td>\n",
       "      <td>297.38</td>\n",
       "      <td>88.67</td>\n",
       "      <td>83.99</td>\n",
       "      <td>166.75</td>\n",
       "      <td>85.84</td>\n",
       "      <td>209.76</td>\n",
       "      <td>331.71</td>\n",
       "      <td>...</td>\n",
       "      <td>62.68</td>\n",
       "      <td>99.31</td>\n",
       "      <td>70.320</td>\n",
       "      <td>56.30</td>\n",
       "      <td>80.29</td>\n",
       "      <td>101.84</td>\n",
       "      <td>148.75</td>\n",
       "      <td>256.10</td>\n",
       "      <td>51.70</td>\n",
       "      <td>134.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06 05:00:00+00:00</th>\n",
       "      <td>84.78</td>\n",
       "      <td>27.32</td>\n",
       "      <td>156.82</td>\n",
       "      <td>299.78</td>\n",
       "      <td>89.40</td>\n",
       "      <td>85.25</td>\n",
       "      <td>179.07</td>\n",
       "      <td>86.33</td>\n",
       "      <td>208.43</td>\n",
       "      <td>333.71</td>\n",
       "      <td>...</td>\n",
       "      <td>62.59</td>\n",
       "      <td>97.23</td>\n",
       "      <td>70.870</td>\n",
       "      <td>56.61</td>\n",
       "      <td>79.81</td>\n",
       "      <td>101.79</td>\n",
       "      <td>147.95</td>\n",
       "      <td>258.01</td>\n",
       "      <td>51.07</td>\n",
       "      <td>133.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07 05:00:00+00:00</th>\n",
       "      <td>85.09</td>\n",
       "      <td>27.22</td>\n",
       "      <td>154.95</td>\n",
       "      <td>298.27</td>\n",
       "      <td>88.87</td>\n",
       "      <td>84.63</td>\n",
       "      <td>180.36</td>\n",
       "      <td>85.87</td>\n",
       "      <td>203.92</td>\n",
       "      <td>333.51</td>\n",
       "      <td>...</td>\n",
       "      <td>62.46</td>\n",
       "      <td>99.46</td>\n",
       "      <td>70.280</td>\n",
       "      <td>56.91</td>\n",
       "      <td>79.50</td>\n",
       "      <td>101.97</td>\n",
       "      <td>147.83</td>\n",
       "      <td>256.47</td>\n",
       "      <td>50.74</td>\n",
       "      <td>133.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08 05:00:00+00:00</th>\n",
       "      <td>85.91</td>\n",
       "      <td>27.84</td>\n",
       "      <td>153.15</td>\n",
       "      <td>303.15</td>\n",
       "      <td>89.52</td>\n",
       "      <td>85.45</td>\n",
       "      <td>178.72</td>\n",
       "      <td>86.21</td>\n",
       "      <td>204.37</td>\n",
       "      <td>337.92</td>\n",
       "      <td>...</td>\n",
       "      <td>62.42</td>\n",
       "      <td>99.19</td>\n",
       "      <td>69.235</td>\n",
       "      <td>57.51</td>\n",
       "      <td>79.78</td>\n",
       "      <td>102.14</td>\n",
       "      <td>149.59</td>\n",
       "      <td>247.63</td>\n",
       "      <td>51.26</td>\n",
       "      <td>133.325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               A    AAL     AAP    AAPL   ABBV    ABC    ABMD  \\\n",
       "time                                                                            \n",
       "2020-01-02 05:00:00+00:00  85.95  29.09  159.40  300.58  89.57  85.09  168.81   \n",
       "2020-01-03 05:00:00+00:00  84.53  27.65  159.48  297.38  88.67  83.99  166.75   \n",
       "2020-01-06 05:00:00+00:00  84.78  27.32  156.82  299.78  89.40  85.25  179.07   \n",
       "2020-01-07 05:00:00+00:00  85.09  27.22  154.95  298.27  88.87  84.63  180.36   \n",
       "2020-01-08 05:00:00+00:00  85.91  27.84  153.15  303.15  89.52  85.45  178.72   \n",
       "\n",
       "                             ABT     ACN    ADBE  ...    XEL    XLNX     XOM  \\\n",
       "time                                              ...                          \n",
       "2020-01-02 05:00:00+00:00  86.94  210.15  334.48  ...  62.38  101.69  70.900   \n",
       "2020-01-03 05:00:00+00:00  85.84  209.76  331.71  ...  62.68   99.31  70.320   \n",
       "2020-01-06 05:00:00+00:00  86.33  208.43  333.71  ...  62.59   97.23  70.870   \n",
       "2020-01-07 05:00:00+00:00  85.87  203.92  333.51  ...  62.46   99.46  70.280   \n",
       "2020-01-08 05:00:00+00:00  86.21  204.37  337.92  ...  62.42   99.19  69.235   \n",
       "\n",
       "                            XRAY    XYL     YUM     ZBH    ZBRA   ZION  \\\n",
       "time                                                                     \n",
       "2020-01-02 05:00:00+00:00  56.94  79.87  102.18  149.20  259.14  52.44   \n",
       "2020-01-03 05:00:00+00:00  56.30  80.29  101.84  148.75  256.10  51.70   \n",
       "2020-01-06 05:00:00+00:00  56.61  79.81  101.79  147.95  258.01  51.07   \n",
       "2020-01-07 05:00:00+00:00  56.91  79.50  101.97  147.83  256.47  50.74   \n",
       "2020-01-08 05:00:00+00:00  57.51  79.78  102.14  149.59  247.63  51.26   \n",
       "\n",
       "                               ZTS  \n",
       "time                                \n",
       "2020-01-02 05:00:00+00:00  134.150  \n",
       "2020-01-03 05:00:00+00:00  134.110  \n",
       "2020-01-06 05:00:00+00:00  133.100  \n",
       "2020-01-07 05:00:00+00:00  133.600  \n",
       "2020-01-08 05:00:00+00:00  133.325  \n",
       "\n",
       "[5 rows x 505 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv_path = Path(\"../Resources/trading_signals.csv\")\n",
    "csv_path = Path (\"./sp500_close_2020-2021.csv\", infer_datetime_format = True,  parse_dates=True, index_col='time')\n",
    "SP500_close = read_csv(csv_path)\n",
    "# raw_data['Mycol'] =  pd.to_datetime(raw_data['Mycol'], format='%d%b%Y:%H:%M:%S.%f')\n",
    "SP500_close['time'] = pd.to_datetime (SP500_close['time'])\n",
    "SP500_close.set_index('time', inplace = True)\n",
    "# SP500_close = SP500_close.iloc[:, 1:]\n",
    "SP500_close.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>A</th>\n",
       "      <th>A.1</th>\n",
       "      <th>A.2</th>\n",
       "      <th>A.3</th>\n",
       "      <th>A.4</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAL.1</th>\n",
       "      <th>AAL.2</th>\n",
       "      <th>AAL.3</th>\n",
       "      <th>...</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZION.1</th>\n",
       "      <th>ZION.2</th>\n",
       "      <th>ZION.3</th>\n",
       "      <th>ZION.4</th>\n",
       "      <th>ZTS</th>\n",
       "      <th>ZTS.1</th>\n",
       "      <th>ZTS.2</th>\n",
       "      <th>ZTS.3</th>\n",
       "      <th>ZTS.4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>open</td>\n",
       "      <td>high</td>\n",
       "      <td>low</td>\n",
       "      <td>close</td>\n",
       "      <td>volume</td>\n",
       "      <td>open</td>\n",
       "      <td>high</td>\n",
       "      <td>low</td>\n",
       "      <td>close</td>\n",
       "      <td>...</td>\n",
       "      <td>open</td>\n",
       "      <td>high</td>\n",
       "      <td>low</td>\n",
       "      <td>close</td>\n",
       "      <td>volume</td>\n",
       "      <td>open</td>\n",
       "      <td>high</td>\n",
       "      <td>low</td>\n",
       "      <td>close</td>\n",
       "      <td>volume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-02 05:00:00+00:00</td>\n",
       "      <td>85.9</td>\n",
       "      <td>86.35</td>\n",
       "      <td>85.2</td>\n",
       "      <td>85.95</td>\n",
       "      <td>1199810</td>\n",
       "      <td>28.98</td>\n",
       "      <td>29.295</td>\n",
       "      <td>28.65</td>\n",
       "      <td>29.09</td>\n",
       "      <td>...</td>\n",
       "      <td>52.36</td>\n",
       "      <td>52.48</td>\n",
       "      <td>51.79</td>\n",
       "      <td>52.44</td>\n",
       "      <td>1307412</td>\n",
       "      <td>132.05</td>\n",
       "      <td>134.28</td>\n",
       "      <td>131.48</td>\n",
       "      <td>134.15</td>\n",
       "      <td>1308668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-03 05:00:00+00:00</td>\n",
       "      <td>84.67</td>\n",
       "      <td>85.33</td>\n",
       "      <td>84.5</td>\n",
       "      <td>84.53</td>\n",
       "      <td>895182</td>\n",
       "      <td>28.27</td>\n",
       "      <td>28.29</td>\n",
       "      <td>27.34</td>\n",
       "      <td>27.65</td>\n",
       "      <td>...</td>\n",
       "      <td>51.41</td>\n",
       "      <td>51.89</td>\n",
       "      <td>51.16</td>\n",
       "      <td>51.7</td>\n",
       "      <td>1012303</td>\n",
       "      <td>132.48</td>\n",
       "      <td>134.91</td>\n",
       "      <td>132.27</td>\n",
       "      <td>134.11</td>\n",
       "      <td>1038786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-06 05:00:00+00:00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.82</td>\n",
       "      <td>83.6</td>\n",
       "      <td>84.78</td>\n",
       "      <td>1380173</td>\n",
       "      <td>27.19</td>\n",
       "      <td>27.4901</td>\n",
       "      <td>27.08</td>\n",
       "      <td>27.32</td>\n",
       "      <td>...</td>\n",
       "      <td>51.08</td>\n",
       "      <td>51.68</td>\n",
       "      <td>50.805</td>\n",
       "      <td>51.07</td>\n",
       "      <td>1048073</td>\n",
       "      <td>133.78</td>\n",
       "      <td>134.065</td>\n",
       "      <td>132.71</td>\n",
       "      <td>133.1</td>\n",
       "      <td>1259478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2526 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Unnamed: 0      A    A.1   A.2    A.3      A.4    AAL  \\\n",
       "0                        NaN   open   high   low  close   volume   open   \n",
       "1                       time    NaN    NaN   NaN    NaN      NaN    NaN   \n",
       "2  2020-01-02 05:00:00+00:00   85.9  86.35  85.2  85.95  1199810  28.98   \n",
       "3  2020-01-03 05:00:00+00:00  84.67  85.33  84.5  84.53   895182  28.27   \n",
       "4  2020-01-06 05:00:00+00:00   84.0  84.82  83.6  84.78  1380173  27.19   \n",
       "\n",
       "     AAL.1  AAL.2  AAL.3  ...   ZION ZION.1  ZION.2 ZION.3   ZION.4     ZTS  \\\n",
       "0     high    low  close  ...   open   high     low  close   volume    open   \n",
       "1      NaN    NaN    NaN  ...    NaN    NaN     NaN    NaN      NaN     NaN   \n",
       "2   29.295  28.65  29.09  ...  52.36  52.48   51.79  52.44  1307412  132.05   \n",
       "3    28.29  27.34  27.65  ...  51.41  51.89   51.16   51.7  1012303  132.48   \n",
       "4  27.4901  27.08  27.32  ...  51.08  51.68  50.805  51.07  1048073  133.78   \n",
       "\n",
       "     ZTS.1   ZTS.2   ZTS.3    ZTS.4  \n",
       "0     high     low   close   volume  \n",
       "1      NaN     NaN     NaN      NaN  \n",
       "2   134.28  131.48  134.15  1308668  \n",
       "3   134.91  132.27  134.11  1038786  \n",
       "4  134.065  132.71   133.1  1259478  \n",
       "\n",
       "[5 rows x 2526 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to rearrang this because it is multi-level\n",
    "# df = pd.read_csv(pd.compat.StringIO(temp), header=[0,1], index_col=[0])\n",
    "csv_path = Path (\"./sp500_2020-2021.csv\",header=[0,1])\n",
    "SP500_all = read_csv(csv_path)\n",
    "SP500_all.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2.  Find Correlation between prices\n",
    "1. create % change \n",
    "2. create fraction of change\n",
    "2. create log # fraction change\n",
    "3. calculate correlation of %change\n",
    "3. calculate correlatio of fraction change\n",
    "4. calculate correlation of log #change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-03 05:00:00+00:00</th>\n",
       "      <td>-0.016521</td>\n",
       "      <td>-0.049502</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>-0.010646</td>\n",
       "      <td>-0.010048</td>\n",
       "      <td>-0.012927</td>\n",
       "      <td>-0.012203</td>\n",
       "      <td>-0.012652</td>\n",
       "      <td>-0.001856</td>\n",
       "      <td>-0.008282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004809</td>\n",
       "      <td>-0.023404</td>\n",
       "      <td>-0.008181</td>\n",
       "      <td>-0.011240</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>-0.003327</td>\n",
       "      <td>-0.003016</td>\n",
       "      <td>-0.011731</td>\n",
       "      <td>-0.014111</td>\n",
       "      <td>-0.000298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06 05:00:00+00:00</th>\n",
       "      <td>0.002958</td>\n",
       "      <td>-0.011935</td>\n",
       "      <td>-0.016679</td>\n",
       "      <td>0.008070</td>\n",
       "      <td>0.008233</td>\n",
       "      <td>0.015002</td>\n",
       "      <td>0.073883</td>\n",
       "      <td>0.005708</td>\n",
       "      <td>-0.006341</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001436</td>\n",
       "      <td>-0.020945</td>\n",
       "      <td>0.007821</td>\n",
       "      <td>0.005506</td>\n",
       "      <td>-0.005978</td>\n",
       "      <td>-0.000491</td>\n",
       "      <td>-0.005378</td>\n",
       "      <td>0.007458</td>\n",
       "      <td>-0.012186</td>\n",
       "      <td>-0.007531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07 05:00:00+00:00</th>\n",
       "      <td>0.003657</td>\n",
       "      <td>-0.003660</td>\n",
       "      <td>-0.011924</td>\n",
       "      <td>-0.005037</td>\n",
       "      <td>-0.005928</td>\n",
       "      <td>-0.007273</td>\n",
       "      <td>0.007204</td>\n",
       "      <td>-0.005328</td>\n",
       "      <td>-0.021638</td>\n",
       "      <td>-0.000599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002077</td>\n",
       "      <td>0.022935</td>\n",
       "      <td>-0.008325</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>-0.003884</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>-0.000811</td>\n",
       "      <td>-0.005969</td>\n",
       "      <td>-0.006462</td>\n",
       "      <td>0.003757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08 05:00:00+00:00</th>\n",
       "      <td>0.009637</td>\n",
       "      <td>0.022777</td>\n",
       "      <td>-0.011617</td>\n",
       "      <td>0.016361</td>\n",
       "      <td>0.007314</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>-0.009093</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>0.002207</td>\n",
       "      <td>0.013223</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000640</td>\n",
       "      <td>-0.002715</td>\n",
       "      <td>-0.014869</td>\n",
       "      <td>0.010543</td>\n",
       "      <td>0.003522</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.011906</td>\n",
       "      <td>-0.034468</td>\n",
       "      <td>0.010248</td>\n",
       "      <td>-0.002058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-09 05:00:00+00:00</th>\n",
       "      <td>0.015714</td>\n",
       "      <td>0.003951</td>\n",
       "      <td>-0.001763</td>\n",
       "      <td>0.021639</td>\n",
       "      <td>0.007708</td>\n",
       "      <td>0.014160</td>\n",
       "      <td>0.028424</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.009003</td>\n",
       "      <td>0.007487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.023490</td>\n",
       "      <td>0.007727</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.008028</td>\n",
       "      <td>-0.006752</td>\n",
       "      <td>-0.004563</td>\n",
       "      <td>0.006828</td>\n",
       "      <td>0.013163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  A       AAL       AAP      AAPL      ABBV  \\\n",
       "time                                                                          \n",
       "2020-01-03 05:00:00+00:00 -0.016521 -0.049502  0.000502 -0.010646 -0.010048   \n",
       "2020-01-06 05:00:00+00:00  0.002958 -0.011935 -0.016679  0.008070  0.008233   \n",
       "2020-01-07 05:00:00+00:00  0.003657 -0.003660 -0.011924 -0.005037 -0.005928   \n",
       "2020-01-08 05:00:00+00:00  0.009637  0.022777 -0.011617  0.016361  0.007314   \n",
       "2020-01-09 05:00:00+00:00  0.015714  0.003951 -0.001763  0.021639  0.007708   \n",
       "\n",
       "                                ABC      ABMD       ABT       ACN      ADBE  \\\n",
       "time                                                                          \n",
       "2020-01-03 05:00:00+00:00 -0.012927 -0.012203 -0.012652 -0.001856 -0.008282   \n",
       "2020-01-06 05:00:00+00:00  0.015002  0.073883  0.005708 -0.006341  0.006029   \n",
       "2020-01-07 05:00:00+00:00 -0.007273  0.007204 -0.005328 -0.021638 -0.000599   \n",
       "2020-01-08 05:00:00+00:00  0.009689 -0.009093  0.003959  0.002207  0.013223   \n",
       "2020-01-09 05:00:00+00:00  0.014160  0.028424  0.002552  0.009003  0.007487   \n",
       "\n",
       "                           ...       XEL      XLNX       XOM      XRAY  \\\n",
       "time                       ...                                           \n",
       "2020-01-03 05:00:00+00:00  ...  0.004809 -0.023404 -0.008181 -0.011240   \n",
       "2020-01-06 05:00:00+00:00  ... -0.001436 -0.020945  0.007821  0.005506   \n",
       "2020-01-07 05:00:00+00:00  ... -0.002077  0.022935 -0.008325  0.005299   \n",
       "2020-01-08 05:00:00+00:00  ... -0.000640 -0.002715 -0.014869  0.010543   \n",
       "2020-01-09 05:00:00+00:00  ...  0.001922  0.023490  0.007727  0.000869   \n",
       "\n",
       "                                XYL       YUM       ZBH      ZBRA      ZION  \\\n",
       "time                                                                          \n",
       "2020-01-03 05:00:00+00:00  0.005259 -0.003327 -0.003016 -0.011731 -0.014111   \n",
       "2020-01-06 05:00:00+00:00 -0.005978 -0.000491 -0.005378  0.007458 -0.012186   \n",
       "2020-01-07 05:00:00+00:00 -0.003884  0.001768 -0.000811 -0.005969 -0.006462   \n",
       "2020-01-08 05:00:00+00:00  0.003522  0.001667  0.011906 -0.034468  0.010248   \n",
       "2020-01-09 05:00:00+00:00  0.004387  0.008028 -0.006752 -0.004563  0.006828   \n",
       "\n",
       "                                ZTS  \n",
       "time                                 \n",
       "2020-01-03 05:00:00+00:00 -0.000298  \n",
       "2020-01-06 05:00:00+00:00 -0.007531  \n",
       "2020-01-07 05:00:00+00:00  0.003757  \n",
       "2020-01-08 05:00:00+00:00 -0.002058  \n",
       "2020-01-09 05:00:00+00:00  0.013163  \n",
       "\n",
       "[5 rows x 505 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pct_change = SP500_close.pct_change().dropna(how='all')\n",
    "# SP500_close.pct_change()\n",
    "df_pct_change.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02 05:00:00+00:00</th>\n",
       "      <td>85.95</td>\n",
       "      <td>29.09</td>\n",
       "      <td>159.40</td>\n",
       "      <td>300.58</td>\n",
       "      <td>89.57</td>\n",
       "      <td>85.09</td>\n",
       "      <td>168.81</td>\n",
       "      <td>86.94</td>\n",
       "      <td>210.15</td>\n",
       "      <td>334.48</td>\n",
       "      <td>...</td>\n",
       "      <td>62.38</td>\n",
       "      <td>101.69</td>\n",
       "      <td>70.900</td>\n",
       "      <td>56.94</td>\n",
       "      <td>79.87</td>\n",
       "      <td>102.18</td>\n",
       "      <td>149.20</td>\n",
       "      <td>259.14</td>\n",
       "      <td>52.44</td>\n",
       "      <td>134.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03 05:00:00+00:00</th>\n",
       "      <td>84.53</td>\n",
       "      <td>27.65</td>\n",
       "      <td>159.48</td>\n",
       "      <td>297.38</td>\n",
       "      <td>88.67</td>\n",
       "      <td>83.99</td>\n",
       "      <td>166.75</td>\n",
       "      <td>85.84</td>\n",
       "      <td>209.76</td>\n",
       "      <td>331.71</td>\n",
       "      <td>...</td>\n",
       "      <td>62.68</td>\n",
       "      <td>99.31</td>\n",
       "      <td>70.320</td>\n",
       "      <td>56.30</td>\n",
       "      <td>80.29</td>\n",
       "      <td>101.84</td>\n",
       "      <td>148.75</td>\n",
       "      <td>256.10</td>\n",
       "      <td>51.70</td>\n",
       "      <td>134.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06 05:00:00+00:00</th>\n",
       "      <td>84.78</td>\n",
       "      <td>27.32</td>\n",
       "      <td>156.82</td>\n",
       "      <td>299.78</td>\n",
       "      <td>89.40</td>\n",
       "      <td>85.25</td>\n",
       "      <td>179.07</td>\n",
       "      <td>86.33</td>\n",
       "      <td>208.43</td>\n",
       "      <td>333.71</td>\n",
       "      <td>...</td>\n",
       "      <td>62.59</td>\n",
       "      <td>97.23</td>\n",
       "      <td>70.870</td>\n",
       "      <td>56.61</td>\n",
       "      <td>79.81</td>\n",
       "      <td>101.79</td>\n",
       "      <td>147.95</td>\n",
       "      <td>258.01</td>\n",
       "      <td>51.07</td>\n",
       "      <td>133.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07 05:00:00+00:00</th>\n",
       "      <td>85.09</td>\n",
       "      <td>27.22</td>\n",
       "      <td>154.95</td>\n",
       "      <td>298.27</td>\n",
       "      <td>88.87</td>\n",
       "      <td>84.63</td>\n",
       "      <td>180.36</td>\n",
       "      <td>85.87</td>\n",
       "      <td>203.92</td>\n",
       "      <td>333.51</td>\n",
       "      <td>...</td>\n",
       "      <td>62.46</td>\n",
       "      <td>99.46</td>\n",
       "      <td>70.280</td>\n",
       "      <td>56.91</td>\n",
       "      <td>79.50</td>\n",
       "      <td>101.97</td>\n",
       "      <td>147.83</td>\n",
       "      <td>256.47</td>\n",
       "      <td>50.74</td>\n",
       "      <td>133.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08 05:00:00+00:00</th>\n",
       "      <td>85.91</td>\n",
       "      <td>27.84</td>\n",
       "      <td>153.15</td>\n",
       "      <td>303.15</td>\n",
       "      <td>89.52</td>\n",
       "      <td>85.45</td>\n",
       "      <td>178.72</td>\n",
       "      <td>86.21</td>\n",
       "      <td>204.37</td>\n",
       "      <td>337.92</td>\n",
       "      <td>...</td>\n",
       "      <td>62.42</td>\n",
       "      <td>99.19</td>\n",
       "      <td>69.235</td>\n",
       "      <td>57.51</td>\n",
       "      <td>79.78</td>\n",
       "      <td>102.14</td>\n",
       "      <td>149.59</td>\n",
       "      <td>247.63</td>\n",
       "      <td>51.26</td>\n",
       "      <td>133.325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               A    AAL     AAP    AAPL   ABBV    ABC    ABMD  \\\n",
       "time                                                                            \n",
       "2020-01-02 05:00:00+00:00  85.95  29.09  159.40  300.58  89.57  85.09  168.81   \n",
       "2020-01-03 05:00:00+00:00  84.53  27.65  159.48  297.38  88.67  83.99  166.75   \n",
       "2020-01-06 05:00:00+00:00  84.78  27.32  156.82  299.78  89.40  85.25  179.07   \n",
       "2020-01-07 05:00:00+00:00  85.09  27.22  154.95  298.27  88.87  84.63  180.36   \n",
       "2020-01-08 05:00:00+00:00  85.91  27.84  153.15  303.15  89.52  85.45  178.72   \n",
       "\n",
       "                             ABT     ACN    ADBE  ...    XEL    XLNX     XOM  \\\n",
       "time                                              ...                          \n",
       "2020-01-02 05:00:00+00:00  86.94  210.15  334.48  ...  62.38  101.69  70.900   \n",
       "2020-01-03 05:00:00+00:00  85.84  209.76  331.71  ...  62.68   99.31  70.320   \n",
       "2020-01-06 05:00:00+00:00  86.33  208.43  333.71  ...  62.59   97.23  70.870   \n",
       "2020-01-07 05:00:00+00:00  85.87  203.92  333.51  ...  62.46   99.46  70.280   \n",
       "2020-01-08 05:00:00+00:00  86.21  204.37  337.92  ...  62.42   99.19  69.235   \n",
       "\n",
       "                            XRAY    XYL     YUM     ZBH    ZBRA   ZION  \\\n",
       "time                                                                     \n",
       "2020-01-02 05:00:00+00:00  56.94  79.87  102.18  149.20  259.14  52.44   \n",
       "2020-01-03 05:00:00+00:00  56.30  80.29  101.84  148.75  256.10  51.70   \n",
       "2020-01-06 05:00:00+00:00  56.61  79.81  101.79  147.95  258.01  51.07   \n",
       "2020-01-07 05:00:00+00:00  56.91  79.50  101.97  147.83  256.47  50.74   \n",
       "2020-01-08 05:00:00+00:00  57.51  79.78  102.14  149.59  247.63  51.26   \n",
       "\n",
       "                               ZTS  \n",
       "time                                \n",
       "2020-01-02 05:00:00+00:00  134.150  \n",
       "2020-01-03 05:00:00+00:00  134.110  \n",
       "2020-01-06 05:00:00+00:00  133.100  \n",
       "2020-01-07 05:00:00+00:00  133.600  \n",
       "2020-01-08 05:00:00+00:00  133.325  \n",
       "\n",
       "[5 rows x 505 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SP500_close.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500_close.shift().head(5)\n",
    "df_change = SP500_close/SP500_close.shift()\n",
    "df_log_change = np.log(SP500_close/SP500_close.shift())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2. Compute Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.443147</td>\n",
       "      <td>0.587213</td>\n",
       "      <td>0.819997</td>\n",
       "      <td>0.712706</td>\n",
       "      <td>0.728070</td>\n",
       "      <td>0.413968</td>\n",
       "      <td>0.811056</td>\n",
       "      <td>0.787407</td>\n",
       "      <td>0.770909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716087</td>\n",
       "      <td>0.752732</td>\n",
       "      <td>0.702827</td>\n",
       "      <td>0.641173</td>\n",
       "      <td>0.820087</td>\n",
       "      <td>0.531354</td>\n",
       "      <td>0.523467</td>\n",
       "      <td>0.815339</td>\n",
       "      <td>0.745251</td>\n",
       "      <td>0.802476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAL</th>\n",
       "      <td>0.443147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.480130</td>\n",
       "      <td>0.430385</td>\n",
       "      <td>0.305095</td>\n",
       "      <td>0.333133</td>\n",
       "      <td>0.359150</td>\n",
       "      <td>0.343987</td>\n",
       "      <td>0.462813</td>\n",
       "      <td>0.267602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342449</td>\n",
       "      <td>0.296774</td>\n",
       "      <td>0.556822</td>\n",
       "      <td>0.438173</td>\n",
       "      <td>0.536077</td>\n",
       "      <td>0.560906</td>\n",
       "      <td>0.564832</td>\n",
       "      <td>0.415976</td>\n",
       "      <td>0.467171</td>\n",
       "      <td>0.400790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAP</th>\n",
       "      <td>0.587213</td>\n",
       "      <td>0.480130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669217</td>\n",
       "      <td>0.612972</td>\n",
       "      <td>0.615328</td>\n",
       "      <td>0.473498</td>\n",
       "      <td>0.627349</td>\n",
       "      <td>0.658271</td>\n",
       "      <td>0.608786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732604</td>\n",
       "      <td>0.614714</td>\n",
       "      <td>0.600658</td>\n",
       "      <td>0.668102</td>\n",
       "      <td>0.730170</td>\n",
       "      <td>0.671056</td>\n",
       "      <td>0.514705</td>\n",
       "      <td>0.608947</td>\n",
       "      <td>0.634158</td>\n",
       "      <td>0.694887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.819997</td>\n",
       "      <td>0.430385</td>\n",
       "      <td>0.669217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773732</td>\n",
       "      <td>0.780393</td>\n",
       "      <td>0.476349</td>\n",
       "      <td>0.833286</td>\n",
       "      <td>0.836114</td>\n",
       "      <td>0.867310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742790</td>\n",
       "      <td>0.742768</td>\n",
       "      <td>0.684204</td>\n",
       "      <td>0.653211</td>\n",
       "      <td>0.805362</td>\n",
       "      <td>0.645901</td>\n",
       "      <td>0.590922</td>\n",
       "      <td>0.810612</td>\n",
       "      <td>0.709257</td>\n",
       "      <td>0.815236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>0.712706</td>\n",
       "      <td>0.305095</td>\n",
       "      <td>0.612972</td>\n",
       "      <td>0.773732</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.753287</td>\n",
       "      <td>0.287458</td>\n",
       "      <td>0.738075</td>\n",
       "      <td>0.773401</td>\n",
       "      <td>0.715894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.649230</td>\n",
       "      <td>0.595783</td>\n",
       "      <td>0.614664</td>\n",
       "      <td>0.729269</td>\n",
       "      <td>0.740274</td>\n",
       "      <td>0.572992</td>\n",
       "      <td>0.597597</td>\n",
       "      <td>0.677072</td>\n",
       "      <td>0.664435</td>\n",
       "      <td>0.776426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             A       AAL       AAP      AAPL      ABBV       ABC      ABMD  \\\n",
       "A     1.000000  0.443147  0.587213  0.819997  0.712706  0.728070  0.413968   \n",
       "AAL   0.443147  1.000000  0.480130  0.430385  0.305095  0.333133  0.359150   \n",
       "AAP   0.587213  0.480130  1.000000  0.669217  0.612972  0.615328  0.473498   \n",
       "AAPL  0.819997  0.430385  0.669217  1.000000  0.773732  0.780393  0.476349   \n",
       "ABBV  0.712706  0.305095  0.612972  0.773732  1.000000  0.753287  0.287458   \n",
       "\n",
       "           ABT       ACN      ADBE  ...       XEL      XLNX       XOM  \\\n",
       "A     0.811056  0.787407  0.770909  ...  0.716087  0.752732  0.702827   \n",
       "AAL   0.343987  0.462813  0.267602  ...  0.342449  0.296774  0.556822   \n",
       "AAP   0.627349  0.658271  0.608786  ...  0.732604  0.614714  0.600658   \n",
       "AAPL  0.833286  0.836114  0.867310  ...  0.742790  0.742768  0.684204   \n",
       "ABBV  0.738075  0.773401  0.715894  ...  0.649230  0.595783  0.614664   \n",
       "\n",
       "          XRAY       XYL       YUM       ZBH      ZBRA      ZION       ZTS  \n",
       "A     0.641173  0.820087  0.531354  0.523467  0.815339  0.745251  0.802476  \n",
       "AAL   0.438173  0.536077  0.560906  0.564832  0.415976  0.467171  0.400790  \n",
       "AAP   0.668102  0.730170  0.671056  0.514705  0.608947  0.634158  0.694887  \n",
       "AAPL  0.653211  0.805362  0.645901  0.590922  0.810612  0.709257  0.815236  \n",
       "ABBV  0.729269  0.740274  0.572992  0.597597  0.677072  0.664435  0.776426  \n",
       "\n",
       "[5 rows x 505 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pct_chgn_corr = df_pct_change.corr()\n",
    "df_pct_chgn_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.443147</td>\n",
       "      <td>0.587213</td>\n",
       "      <td>0.819997</td>\n",
       "      <td>0.712706</td>\n",
       "      <td>0.728070</td>\n",
       "      <td>0.413968</td>\n",
       "      <td>0.811056</td>\n",
       "      <td>0.787407</td>\n",
       "      <td>0.770909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716087</td>\n",
       "      <td>0.752732</td>\n",
       "      <td>0.702827</td>\n",
       "      <td>0.641173</td>\n",
       "      <td>0.820087</td>\n",
       "      <td>0.531354</td>\n",
       "      <td>0.523467</td>\n",
       "      <td>0.815339</td>\n",
       "      <td>0.745251</td>\n",
       "      <td>0.802476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAL</th>\n",
       "      <td>0.443147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.480130</td>\n",
       "      <td>0.430385</td>\n",
       "      <td>0.305095</td>\n",
       "      <td>0.333133</td>\n",
       "      <td>0.359150</td>\n",
       "      <td>0.343987</td>\n",
       "      <td>0.462813</td>\n",
       "      <td>0.267602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342449</td>\n",
       "      <td>0.296774</td>\n",
       "      <td>0.556822</td>\n",
       "      <td>0.438173</td>\n",
       "      <td>0.536077</td>\n",
       "      <td>0.560906</td>\n",
       "      <td>0.564832</td>\n",
       "      <td>0.415976</td>\n",
       "      <td>0.467171</td>\n",
       "      <td>0.400790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAP</th>\n",
       "      <td>0.587213</td>\n",
       "      <td>0.480130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669217</td>\n",
       "      <td>0.612972</td>\n",
       "      <td>0.615328</td>\n",
       "      <td>0.473498</td>\n",
       "      <td>0.627349</td>\n",
       "      <td>0.658271</td>\n",
       "      <td>0.608786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732604</td>\n",
       "      <td>0.614714</td>\n",
       "      <td>0.600658</td>\n",
       "      <td>0.668102</td>\n",
       "      <td>0.730170</td>\n",
       "      <td>0.671056</td>\n",
       "      <td>0.514705</td>\n",
       "      <td>0.608947</td>\n",
       "      <td>0.634158</td>\n",
       "      <td>0.694887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.819997</td>\n",
       "      <td>0.430385</td>\n",
       "      <td>0.669217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773732</td>\n",
       "      <td>0.780393</td>\n",
       "      <td>0.476349</td>\n",
       "      <td>0.833286</td>\n",
       "      <td>0.836114</td>\n",
       "      <td>0.867310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742790</td>\n",
       "      <td>0.742768</td>\n",
       "      <td>0.684204</td>\n",
       "      <td>0.653211</td>\n",
       "      <td>0.805362</td>\n",
       "      <td>0.645901</td>\n",
       "      <td>0.590922</td>\n",
       "      <td>0.810612</td>\n",
       "      <td>0.709257</td>\n",
       "      <td>0.815236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>0.712706</td>\n",
       "      <td>0.305095</td>\n",
       "      <td>0.612972</td>\n",
       "      <td>0.773732</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.753287</td>\n",
       "      <td>0.287458</td>\n",
       "      <td>0.738075</td>\n",
       "      <td>0.773401</td>\n",
       "      <td>0.715894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.649230</td>\n",
       "      <td>0.595783</td>\n",
       "      <td>0.614664</td>\n",
       "      <td>0.729269</td>\n",
       "      <td>0.740274</td>\n",
       "      <td>0.572992</td>\n",
       "      <td>0.597597</td>\n",
       "      <td>0.677072</td>\n",
       "      <td>0.664435</td>\n",
       "      <td>0.776426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             A       AAL       AAP      AAPL      ABBV       ABC      ABMD  \\\n",
       "A     1.000000  0.443147  0.587213  0.819997  0.712706  0.728070  0.413968   \n",
       "AAL   0.443147  1.000000  0.480130  0.430385  0.305095  0.333133  0.359150   \n",
       "AAP   0.587213  0.480130  1.000000  0.669217  0.612972  0.615328  0.473498   \n",
       "AAPL  0.819997  0.430385  0.669217  1.000000  0.773732  0.780393  0.476349   \n",
       "ABBV  0.712706  0.305095  0.612972  0.773732  1.000000  0.753287  0.287458   \n",
       "\n",
       "           ABT       ACN      ADBE  ...       XEL      XLNX       XOM  \\\n",
       "A     0.811056  0.787407  0.770909  ...  0.716087  0.752732  0.702827   \n",
       "AAL   0.343987  0.462813  0.267602  ...  0.342449  0.296774  0.556822   \n",
       "AAP   0.627349  0.658271  0.608786  ...  0.732604  0.614714  0.600658   \n",
       "AAPL  0.833286  0.836114  0.867310  ...  0.742790  0.742768  0.684204   \n",
       "ABBV  0.738075  0.773401  0.715894  ...  0.649230  0.595783  0.614664   \n",
       "\n",
       "          XRAY       XYL       YUM       ZBH      ZBRA      ZION       ZTS  \n",
       "A     0.641173  0.820087  0.531354  0.523467  0.815339  0.745251  0.802476  \n",
       "AAL   0.438173  0.536077  0.560906  0.564832  0.415976  0.467171  0.400790  \n",
       "AAP   0.668102  0.730170  0.671056  0.514705  0.608947  0.634158  0.694887  \n",
       "AAPL  0.653211  0.805362  0.645901  0.590922  0.810612  0.709257  0.815236  \n",
       "ABBV  0.729269  0.740274  0.572992  0.597597  0.677072  0.664435  0.776426  \n",
       "\n",
       "[5 rows x 505 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_change_corr = df_change.corr()\n",
    "df_change_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.447760</td>\n",
       "      <td>0.581251</td>\n",
       "      <td>0.818401</td>\n",
       "      <td>0.712669</td>\n",
       "      <td>0.717333</td>\n",
       "      <td>0.414445</td>\n",
       "      <td>0.805092</td>\n",
       "      <td>0.789330</td>\n",
       "      <td>0.770999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700958</td>\n",
       "      <td>0.744983</td>\n",
       "      <td>0.709445</td>\n",
       "      <td>0.648652</td>\n",
       "      <td>0.812906</td>\n",
       "      <td>0.542518</td>\n",
       "      <td>0.537930</td>\n",
       "      <td>0.814061</td>\n",
       "      <td>0.750312</td>\n",
       "      <td>0.801734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAL</th>\n",
       "      <td>0.447760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.471541</td>\n",
       "      <td>0.416506</td>\n",
       "      <td>0.299832</td>\n",
       "      <td>0.334056</td>\n",
       "      <td>0.345857</td>\n",
       "      <td>0.319942</td>\n",
       "      <td>0.460006</td>\n",
       "      <td>0.280687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335307</td>\n",
       "      <td>0.294660</td>\n",
       "      <td>0.553593</td>\n",
       "      <td>0.435042</td>\n",
       "      <td>0.547236</td>\n",
       "      <td>0.525348</td>\n",
       "      <td>0.552695</td>\n",
       "      <td>0.411514</td>\n",
       "      <td>0.464487</td>\n",
       "      <td>0.384022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAP</th>\n",
       "      <td>0.581251</td>\n",
       "      <td>0.471541</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.674323</td>\n",
       "      <td>0.625709</td>\n",
       "      <td>0.617600</td>\n",
       "      <td>0.473615</td>\n",
       "      <td>0.626373</td>\n",
       "      <td>0.655899</td>\n",
       "      <td>0.624832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745070</td>\n",
       "      <td>0.611149</td>\n",
       "      <td>0.604328</td>\n",
       "      <td>0.676629</td>\n",
       "      <td>0.737239</td>\n",
       "      <td>0.667077</td>\n",
       "      <td>0.508707</td>\n",
       "      <td>0.609771</td>\n",
       "      <td>0.629720</td>\n",
       "      <td>0.691378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.818401</td>\n",
       "      <td>0.416506</td>\n",
       "      <td>0.674323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.780399</td>\n",
       "      <td>0.780847</td>\n",
       "      <td>0.468285</td>\n",
       "      <td>0.830937</td>\n",
       "      <td>0.837551</td>\n",
       "      <td>0.873413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744959</td>\n",
       "      <td>0.739347</td>\n",
       "      <td>0.694480</td>\n",
       "      <td>0.668258</td>\n",
       "      <td>0.804657</td>\n",
       "      <td>0.651628</td>\n",
       "      <td>0.598214</td>\n",
       "      <td>0.808067</td>\n",
       "      <td>0.715565</td>\n",
       "      <td>0.818120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>0.712669</td>\n",
       "      <td>0.299832</td>\n",
       "      <td>0.625709</td>\n",
       "      <td>0.780399</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.756530</td>\n",
       "      <td>0.286213</td>\n",
       "      <td>0.741185</td>\n",
       "      <td>0.771540</td>\n",
       "      <td>0.726565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655394</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.622101</td>\n",
       "      <td>0.738113</td>\n",
       "      <td>0.742644</td>\n",
       "      <td>0.587713</td>\n",
       "      <td>0.603224</td>\n",
       "      <td>0.679809</td>\n",
       "      <td>0.668854</td>\n",
       "      <td>0.788051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             A       AAL       AAP      AAPL      ABBV       ABC      ABMD  \\\n",
       "A     1.000000  0.447760  0.581251  0.818401  0.712669  0.717333  0.414445   \n",
       "AAL   0.447760  1.000000  0.471541  0.416506  0.299832  0.334056  0.345857   \n",
       "AAP   0.581251  0.471541  1.000000  0.674323  0.625709  0.617600  0.473615   \n",
       "AAPL  0.818401  0.416506  0.674323  1.000000  0.780399  0.780847  0.468285   \n",
       "ABBV  0.712669  0.299832  0.625709  0.780399  1.000000  0.756530  0.286213   \n",
       "\n",
       "           ABT       ACN      ADBE  ...       XEL      XLNX       XOM  \\\n",
       "A     0.805092  0.789330  0.770999  ...  0.700958  0.744983  0.709445   \n",
       "AAL   0.319942  0.460006  0.280687  ...  0.335307  0.294660  0.553593   \n",
       "AAP   0.626373  0.655899  0.624832  ...  0.745070  0.611149  0.604328   \n",
       "AAPL  0.830937  0.837551  0.873413  ...  0.744959  0.739347  0.694480   \n",
       "ABBV  0.741185  0.771540  0.726565  ...  0.655394  0.596115  0.622101   \n",
       "\n",
       "          XRAY       XYL       YUM       ZBH      ZBRA      ZION       ZTS  \n",
       "A     0.648652  0.812906  0.542518  0.537930  0.814061  0.750312  0.801734  \n",
       "AAL   0.435042  0.547236  0.525348  0.552695  0.411514  0.464487  0.384022  \n",
       "AAP   0.676629  0.737239  0.667077  0.508707  0.609771  0.629720  0.691378  \n",
       "AAPL  0.668258  0.804657  0.651628  0.598214  0.808067  0.715565  0.818120  \n",
       "ABBV  0.738113  0.742644  0.587713  0.603224  0.679809  0.668854  0.788051  \n",
       "\n",
       "[5 rows x 505 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_log_chng_corr = df_log_change.corr()\n",
    "df_log_chng_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OTIS    2.220446e-16\n",
       "IR      2.220446e-16\n",
       "NLOK    2.498002e-16\n",
       "CARR    3.330669e-16\n",
       "HWM     3.330669e-16\n",
       "            ...     \n",
       "DOV     1.332268e-15\n",
       "F       1.332268e-15\n",
       "LUMN             NaN\n",
       "OGN              NaN\n",
       "VTRS             NaN\n",
       "Length: 505, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dif_pct_chng_chg = df_pct_chgn_corr - df_change_corr\n",
    "df_dif_pct_chng_chg.max().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CARR    0.015843\n",
       "KR      0.019835\n",
       "HWM     0.024264\n",
       "CLX     0.031830\n",
       "RTX     0.035876\n",
       "          ...   \n",
       "PH      0.161192\n",
       "IR      0.161192\n",
       "LUMN         NaN\n",
       "OGN          NaN\n",
       "VTRS         NaN\n",
       "Length: 505, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dif_pct_chng_log_chng = df_pct_chgn_corr - df_log_chng_corr\n",
    "df_dif_pct_chng_log_chng.max().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3. Set Up LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 create some data here from previous section.\n",
    "can do as any number of data in the section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02 05:00:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03 05:00:00+00:00</th>\n",
       "      <td>-0.016659</td>\n",
       "      <td>-0.050769</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>-0.010703</td>\n",
       "      <td>-0.010099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06 05:00:00+00:00</th>\n",
       "      <td>0.002953</td>\n",
       "      <td>-0.012007</td>\n",
       "      <td>-0.016820</td>\n",
       "      <td>0.008038</td>\n",
       "      <td>0.008199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07 05:00:00+00:00</th>\n",
       "      <td>0.003650</td>\n",
       "      <td>-0.003667</td>\n",
       "      <td>-0.011996</td>\n",
       "      <td>-0.005050</td>\n",
       "      <td>-0.005946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08 05:00:00+00:00</th>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.022522</td>\n",
       "      <td>-0.011685</td>\n",
       "      <td>0.016229</td>\n",
       "      <td>0.007287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  A       AAL       AAP      AAPL      ABBV\n",
       "time                                                                       \n",
       "2020-01-02 05:00:00+00:00       NaN       NaN       NaN       NaN       NaN\n",
       "2020-01-03 05:00:00+00:00 -0.016659 -0.050769  0.000502 -0.010703 -0.010099\n",
       "2020-01-06 05:00:00+00:00  0.002953 -0.012007 -0.016820  0.008038  0.008199\n",
       "2020-01-07 05:00:00+00:00  0.003650 -0.003667 -0.011996 -0.005050 -0.005946\n",
       "2020-01-08 05:00:00+00:00  0.009591  0.022522 -0.011685  0.016229  0.007287"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_cols = 5\n",
    "raw_df = df_log_change.iloc[:, : num_of_cols]\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>-0.016659</td>\n",
       "      <td>-0.050769</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>-0.010703</td>\n",
       "      <td>-0.010099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A       AAL       AAP      AAPL      ABBV\n",
       "2020-01-02       NaN       NaN       NaN       NaN       NaN\n",
       "2020-01-03 -0.016659 -0.050769  0.000502 -0.010703 -0.010099"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_index_df = raw_df.copy()\n",
    "# test.index = pd.to_datetime(test.index, format = '%Y-%m-%d')\n",
    "date_index_df.index = date_index_df.index.strftime('%Y-%m-%d')\n",
    "date_index_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">run till here Now</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Convert Raw DF to LSTM Data\n",
    "assume that last column is target column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scale_data (in_df):\n",
    "#     '''\n",
    "#     comments here\n",
    "#     '''\n",
    "#     global scaler\n",
    "#     dataset = in_df.copy().dropna(how='all')\n",
    "#     values = dataset.values\n",
    "#     # integer encode direction\n",
    "#     encoder = LabelEncoder()\n",
    "#     #     # column 4 is the direction it is encode no encoding in this\n",
    "#     #     values[:,4] = encoder.fit_transform(values[:,4])\n",
    "#     # ensure all data is float\n",
    "#     values = values.astype('float32')\n",
    "#     # normalize features\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     scaled = scaler.fit_transform(values)\n",
    "    \n",
    "#     return scaled, scaler\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_data = scale_data(raw_df)\n",
    "# scaled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from MV LSTM from \n",
    "# # https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\n",
    "# # convert series to supervised learning\n",
    "# def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "#     '''\n",
    "#     n_in - negative periods\n",
    "#     n_out - is positive periods\n",
    "#     need to add validation of n_in and n_out\n",
    "#     '''\n",
    "#     n_vars = 1 if type(data) is list else data.shape[1]\n",
    "#     df = DataFrame(data)\n",
    "#     cols, names = list(), list()\n",
    "#     # input sequence (t-n, ... t-1)\n",
    "#     for i in range(n_in, 0, -1):\n",
    "#         cols.append(df.shift(i))\n",
    "#         names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "#     # forecast sequence (t, t+1, ... t+n)\n",
    "#     for i in range(0, n_out):\n",
    "#         cols.append(df.shift(-i))\n",
    "#         if i == 0:\n",
    "#             names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "#         else:\n",
    "#             names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "#     # put it all together\n",
    "#     agg = concat(cols, axis=1)\n",
    "#     agg.columns = names\n",
    "#     # drop rows with NaN values\n",
    "#     if dropnan:\n",
    "#         agg.dropna(inplace=True)\n",
    "#     return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue is with dropping columsn to adding back is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def conv_to_LSTM_input(in_df, in_prior_period=1, in_lag_period=1, dropnan=True):\n",
    "#     '''\n",
    "#     convert a dataframe into data structure for LSTM\n",
    "#     call scale_data to scale the data\n",
    "#     series_to_supervised to convert it for LSTM\n",
    "#     NEED to undertand and tune the drop\n",
    "    \n",
    "#     '''\n",
    "\n",
    "#     scaled_data, scaler = scale_data(in_df)\n",
    "    \n",
    "#     #debug \n",
    "# #     print (f'scaled shape: {scaled_data.shape}')\n",
    "    \n",
    "#     lstm_input = series_to_supervised (scaled_data, in_prior_period, in_lag_period, dropnan)\n",
    "    \n",
    "#     #drop the items in the end\n",
    "#     #subtract number of columns\n",
    "#     num_col_to_drop = lstm_input.shape[1] - scaled_data.shape[1]\n",
    "#     #drop the columns at the end\n",
    "#     lstm_input = lstm_input.iloc[:, : - num_col_to_drop]\n",
    "#     return lstm_input, scaler\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_input, scaler1 = conv_to_LSTM_input(raw_df)\n",
    "# print (f'input_lstm shape: {lstm_input.shape}\\n')\n",
    "# print (f'raw_shape: {raw_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Code to fix**\n",
    "series_to_supervised adds additional colummns these are not in the scalling so cannot inverse scael\n",
    "two possible solutions\n",
    "1. reverse the scalling order\n",
    "2. figure out why columns are dropped.\n",
    "3. Need to put scale and inverse in same routnie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">Break earlier</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Split in to train test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def spit_df_LSTM (in_df, test_fract = 0.7):\n",
    "#     '''\n",
    "#     takes a dataframe and creat values ready for LSTM\n",
    "#     in_df\n",
    "#     test_frct\n",
    "#     '''\n",
    "#     values = in_df.values\n",
    "#     split = int(test_fract * len(values))\n",
    "#     train = values[:split, :]\n",
    "#     test = values [split:, :]\n",
    "#     # split into input and outputs\n",
    "#     train_X, train_y = train[:, :-1], train[:, -1]\n",
    "#     test_X, test_y = test[:, :-1], test[:, -1]\n",
    "#     train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "#     test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "#     return train_X, train_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X, train_y, test_X, test_y = spit_df_LSTM(lstm_input)\n",
    "# # print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_lstm(train_X, train_y, test_X, test_y):\n",
    "#     '''\n",
    "#     run LSTM\n",
    "#     do hyper parameter tuning later\n",
    "#     '''\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "#     model.add(Dense(1))\n",
    "#     model.compile(loss='mae', optimizer='adam')\n",
    "#     # fit network\n",
    "#     history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=0, shuffle=False)\n",
    "#     # plot history\n",
    "#     pyplot.plot(history.history['loss'], label='train')\n",
    "#     pyplot.plot(history.history['val_loss'], label='test')\n",
    "#     pyplot.legend()\n",
    "#     pyplot.show()\n",
    "#     return (model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_lstm_1(train_X, train_y, test_X, test_y, scaler):\n",
    "#     '''\n",
    "#     run LSTM\n",
    "#     do hyper parameter tuning later\n",
    "#     '''\n",
    "#     model = Sequential()\n",
    "#     model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "#     model.add(Dense(1))\n",
    "#     model.compile(loss='mae', optimizer='adam')\n",
    "#     # fit network\n",
    "#     history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=0, shuffle=False)\n",
    "#     # plot history\n",
    "#     pyplot.plot(history.history['loss'], label='train')\n",
    "#     pyplot.plot(history.history['val_loss'], label='test')\n",
    "#     pyplot.legend()\n",
    "#     pyplot.show()\n",
    "#     yhat = model.predict(test_X)\n",
    "#     # yhat = test_model.predict(test_X)\n",
    "#     test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "    \n",
    "#     #debug\n",
    "#     print (f'test_X Shape: {test_X.shape}\\n')\n",
    "    \n",
    "#     # invert scaling for forecast\n",
    "#     inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "    \n",
    "#     #debug\n",
    "#     print (f'inv_yhat Shape: {inv_yhat.shape}\\n')\n",
    "    \n",
    "#     inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "#     inv_yhat = inv_yhat[:,0]\n",
    "#     # invert scaling for actual\n",
    "#     test_y = test_y.reshape((len(test_y), 1))\n",
    "#     inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "#     inv_y = scaler.inverse_transform(inv_y)\n",
    "#     inv_y = inv_y[:,0]\n",
    "#     # calculate RMSE\n",
    "#     rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "#     print('Test RMSE: %.3f' % rmse)\n",
    "\n",
    "#     return (model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model = run_lstm_1(train_X, train_y, test_X, test_y, scaler1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # put rmse results in code\n",
    "# yhat = test_model.predict(test_X)\n",
    "# test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# # invert scaling for forecast\n",
    "# inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (f'yhat: {yhat}\\n')\n",
    "# print (f'test_X {test_X}\\n')\n",
    "# print (f'inv_yhat: {inv_yhat}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "# y_pred = scaler.inverse_transform (yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yhat = test_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #...\n",
    "# # make a prediction\n",
    "# # scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# yhat = model.predict(test_X)\n",
    "# # yhat = test_model.predict(test_X)\n",
    "# test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# # invert scaling for forecast\n",
    "# inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "# inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "# inv_yhat = inv_yhat[:,0]\n",
    "# # invert scaling for actual\n",
    "# test_y = test_y.reshape((len(test_y), 1))\n",
    "# inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "# inv_y = scaler.inverse_transform(inv_y)\n",
    "# inv_y = inv_y[:,0]\n",
    "# # calculate RMSE\n",
    "# rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "# print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 bring LSTM as one cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 3.4.1 oringinal code Don ot use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    " \n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    " \n",
    "# load dataset\n",
    "dataset = read_csv('pollution.csv', header=0, index_col=0)\n",
    "values = dataset.values\n",
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "values[:,4] = encoder.fit_transform(values[:,4])\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)\n",
    "print(reframed.head())\n",
    " \n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 365 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    " \n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    " \n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from oringial source. Can be removed\n",
    "# from math import sqrt\n",
    "# from numpy import concatenate\n",
    "# from matplotlib import pyplot\n",
    "# from pandas import read_csv\n",
    "# from pandas import DataFrame\n",
    "# from pandas import concat\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import LSTM\n",
    " \n",
    "# # convert series to supervised learning\n",
    "# def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "# \tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "# \tdf = DataFrame(data)\n",
    "# \tcols, names = list(), list()\n",
    "# \t# input sequence (t-n, ... t-1)\n",
    "# \tfor i in range(n_in, 0, -1):\n",
    "# \t\tcols.append(df.shift(i))\n",
    "# \t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "# \t# forecast sequence (t, t+1, ... t+n)\n",
    "# \tfor i in range(0, n_out):\n",
    "# \t\tcols.append(df.shift(-i))\n",
    "# \t\tif i == 0:\n",
    "# \t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "# \t\telse:\n",
    "# \t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "# \t# put it all together\n",
    "# \tagg = concat(cols, axis=1)\n",
    "# \tagg.columns = names\n",
    "# \t# drop rows with NaN values\n",
    "# \tif dropnan:\n",
    "# \t\tagg.dropna(inplace=True)\n",
    "# \treturn agg\n",
    " \n",
    "# # load dataset\n",
    "# dataset = read_csv('pollution.csv', header=0, index_col=0)\n",
    "# values = dataset.values\n",
    "# # integer encode direction\n",
    "# encoder = LabelEncoder()\n",
    "# values[:,4] = encoder.fit_transform(values[:,4])\n",
    "# # ensure all data is float\n",
    "# values = values.astype('float32')\n",
    "# # normalize features\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# scaled = scaler.fit_transform(values)\n",
    "# # frame as supervised learning\n",
    "# reframed = series_to_supervised(scaled, 1, 1)\n",
    "# # drop columns we don't want to predict\n",
    "# reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)\n",
    "# print(reframed.head())\n",
    " \n",
    "# # split into train and test sets\n",
    "# values = reframed.values\n",
    "# n_train_hours = 365 * 24\n",
    "# train = values[:n_train_hours, :]\n",
    "# test = values[n_train_hours:, :]\n",
    "# # split into input and outputs\n",
    "# train_X, train_y = train[:, :-1], train[:, -1]\n",
    "# test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# # reshape input to be 3D [samples, timesteps, features]\n",
    "# train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "# test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "# print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    " \n",
    "# # design network\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "# model.add(Dense(1))\n",
    "# model.compile(loss='mae', optimizer='adam')\n",
    "# # fit network\n",
    "# history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# # plot history\n",
    "# pyplot.plot(history.history['loss'], label='train')\n",
    "# pyplot.plot(history.history['val_loss'], label='test')\n",
    "# pyplot.legend()\n",
    "# pyplot.show()\n",
    " \n",
    "# # make a prediction\n",
    "# yhat = model.predict(test_X)\n",
    "# test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# # invert scaling for forecast\n",
    "# inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "# inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "# inv_yhat = inv_yhat[:,0]\n",
    "# # invert scaling for actual\n",
    "# test_y = test_y.reshape((len(test_y), 1))\n",
    "# inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "# inv_y = scaler.inverse_transform(inv_y)\n",
    "# inv_y = inv_y[:,0]\n",
    "# # calculate RMSE\n",
    "# rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "# print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 Modifed Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape: (84, 5)\n",
      "reframe shape: (82, 6)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv_y shape: (25, 5)\n",
      "Test RMSE: 0.039\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    " \n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    " \n",
    "# load dataset\n",
    "# dataset = read_csv('pollution.csv', header=0, index_col=0)\n",
    "dataset = raw_df\n",
    "values = dataset.values\n",
    "# integer encode direction\n",
    "\n",
    "# take this out\n",
    "# encoder = LabelEncoder()\n",
    "# values[:,4] = encoder.fit_transform(values[:,4])\n",
    "\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "\n",
    "# debug\n",
    "print (f'value shape: {values.shape}') #debug\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "\n",
    "# redo this secttion\n",
    "# reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)\n",
    "## num_col_to_drop = lstm_input.shape[1] - scaled_data.shape[1]\n",
    "#### drop the columns at the end\n",
    "## lstm_input = lstm_input.iloc[:, : - num_col_to_drop]\n",
    "\n",
    "#above \n",
    "#calculate the number of columns to drop\n",
    "num_col_to_drop =  reframed.shape[1] - dataset.shape[1] -1\n",
    "# drop the clast columns\n",
    "reframed = reframed.iloc[:, : -num_col_to_drop]\n",
    "print (f'reframe shape: {reframed.shape}')\n",
    "#\n",
    "\n",
    "# print(reframed.head())\n",
    " \n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "\n",
    "# redo this section\n",
    "# n_train_hours = 365 * 24\n",
    "# train = values[:n_train_hours, :]\n",
    "# test = values[n_train_hours:, :]\n",
    "\n",
    "# redone here\n",
    "# set test_fraction (set it to 0.7)\n",
    "test_fract = 0.7\n",
    "split = int(test_fract * len(values))\n",
    "train = values[:split, :]\n",
    "test = values [split:, :]\n",
    "\n",
    "\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "# print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    " \n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "# change verbose to zo\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=0, shuffle=False)\n",
    "\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    " \n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "\n",
    "# debug\n",
    "print (f'inv_y shape: {inv_yhat.shape}')\n",
    "\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4.0 Read infor from newsapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Sample Code from <br>\n",
    "https://towardsdatascience.com/get-the-latest-news-using-python-and-performing-analysis-on-it-using-wordclouds-b4541b3b14fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsapi import NewsApiClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for the NewsAPI import. Now initializing a variable for the NewsAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsapi = NewsApiClient(api_key=api_key)\n",
    "from pandas.io.json \n",
    "import json_normalizeimport pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We will use Beautiful Soup package in Python to help clean up the HTML tags from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s see the practical use.\n",
    "\n",
    "Latest News\n",
    "\n",
    "To get the latest news:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_headlines():    \n",
    "   country=input(\"Which country are you interested in?\") \n",
    "   category=input(\"\"\"Which category are you interested in? \\nHere \n",
    "   are the categories to choose from:\\nbusiness\\nentertainment   \n",
    "   \\ngeneral\\nhealth\\nscience\\ntechnology\"\"\")        \n",
    "   top_headlines =newsapi.get_top_headlines(category=category,\n",
    "   language='en',country=country)     \n",
    "   top_headlines=json_normalize(top_headlines['articles'])   \n",
    "   newdf=top_headlines[[\"title\",\"url\"]]    \n",
    "   dic=newdf.set_index('title')['url'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s talk about what this piece of code does. I have written a function called top_headlines. I take in two inputs, country and category. When I supply an input to the country you would have to write it in a specific format. The country parameter in the News API follows this code system:\n",
    "\n",
    "USA is “us”, the United Kingdom is “gb”, India is “in”. For symbols of other countries refer to the link above.\n",
    "\n",
    "In the code itself, I have mentioned how we can supply an input to the category parameter. “general” for general news, “sports” for sports news, and so on.\n",
    "\n",
    "Using get_top_headlines you can get the latest news. Now, the output is in JSON so I wanted to convert it into a Dataframe. So, I used the json_normalize method which I imported earlier in this tutorial. I am then storing that into a new Dataframe with only a few select columns from the list of columns returned in the JSON output.\n",
    "\n",
    "Then I decided that I want to make sense of this news information. I took a used case to see how the opinion of the media changes over time for a particular timeframe. News API has a paid version which offers up to 2 years worth of information. In the free version, you can retrieve up to 30 days worth of news which is the timeframe that I chose as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for a particular topic\n",
    "\n",
    "To do this analysis, we need to use this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_everything(query,language,sort_by='relevancy',from_param,to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this means is it gets everything related to a particular search query. Let’s say you want to try to get every piece of information regarding the hottest topic in the world today, COVID-19 or Coronavirus, you would specify so in the “query” parameter in the above function.\n",
    "\n",
    "The “from_param” parameter and “to” parameter in the above function are the date parameters. It is asking you to specify the timeframe for which you want to get results for the search query. Since I mentioned, I want to get all results for a period of 30 days which is the maximum allowed timeframe for the free version, I will specify the from_param as the day 30 days before today’s date. However, I need to write this in a loop so that I can ensure I am getting every day.\n",
    "\n",
    "So, I built a date function first which helps me with this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creates a list of dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "def date(base):    \n",
    "    date_list=[]    \n",
    "    yr=datetime.today().year    \n",
    "    if (yr%400)==0 or ((yr%100!=0) and (yr%4==0)):          \n",
    "        numdays=366        \n",
    "        date_list.append([base - timedelta(days=x) for x in    \n",
    "        range(366)])   \n",
    "    else:        \n",
    "        numdays=365        \n",
    "        date_list.append([base - timedelta(days=x) for x in    \n",
    "        range(365)])    \n",
    "        newlist=[]    \n",
    "        for i in date_list:        \n",
    "           for j in sorted(i):            \n",
    "               newlist.append(j)    \n",
    "        return newlist \n",
    "def last_30(base):     \n",
    "    date_list=[base - timedelta(days=x) for x in range(30)]      \n",
    "    return sorted(date_list)  \n",
    "def from_dt(x):    \n",
    "    from_dt=[]    \n",
    "    for i in range(len(x)):          \n",
    "        from_dt.append(last_30(datetime.today())[i-1].date())         \n",
    "    return from_dt        \n",
    "def to_dt(x):    \n",
    "    to_dt=[]    \n",
    "    for i in range(len(x)):        \n",
    "        to_dt.append(last_30(datetime.today())[i].date())    \n",
    "    return to_dt\n",
    "from_list=from_dt(last_30(datetime.today()))\n",
    "to_list=to_dt(last_30(datetime.today()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.date(2021, 8, 24),\n",
       " datetime.date(2021, 7, 26),\n",
       " datetime.date(2021, 7, 27),\n",
       " datetime.date(2021, 7, 28),\n",
       " datetime.date(2021, 7, 29),\n",
       " datetime.date(2021, 7, 30),\n",
       " datetime.date(2021, 7, 31),\n",
       " datetime.date(2021, 8, 1),\n",
       " datetime.date(2021, 8, 2),\n",
       " datetime.date(2021, 8, 3),\n",
       " datetime.date(2021, 8, 4),\n",
       " datetime.date(2021, 8, 5),\n",
       " datetime.date(2021, 8, 6),\n",
       " datetime.date(2021, 8, 7),\n",
       " datetime.date(2021, 8, 8),\n",
       " datetime.date(2021, 8, 9),\n",
       " datetime.date(2021, 8, 10),\n",
       " datetime.date(2021, 8, 11),\n",
       " datetime.date(2021, 8, 12),\n",
       " datetime.date(2021, 8, 13),\n",
       " datetime.date(2021, 8, 14),\n",
       " datetime.date(2021, 8, 15),\n",
       " datetime.date(2021, 8, 16),\n",
       " datetime.date(2021, 8, 17),\n",
       " datetime.date(2021, 8, 18),\n",
       " datetime.date(2021, 8, 19),\n",
       " datetime.date(2021, 8, 20),\n",
       " datetime.date(2021, 8, 21),\n",
       " datetime.date(2021, 8, 22),\n",
       " datetime.date(2021, 8, 23)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first date function (date) that I have built is a more general date function where I want to use it for a large timeframe if needed. I am getting a list of all days using the first date function. I need only 30 days so I made sure to do that using last_30. This will give me a list of the last 30 days from the current day and time. Moving on to the from_dt function, it is specifically for the from_param for the get_everything function mentioned above. This is the start of the timeframe for which you need all the news articles and to_dt is the end date.\n",
    "\n",
    "I now have two separate lists for start and end date respectively.\n",
    "\n",
    "Now we will work on the query parameter which is the search term for the get_everything function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(query): \n",
    "    newd={}    \n",
    "    newdf=pd.DataFrame()    \n",
    "    for (from_dt,to_dt) in zip(from_list,to_list):           \n",
    "        all_articles = newsapi.get_everything(q=query,language='en',\n",
    "        sort_by='relevancy',from_param=from_dt,to=to_dt)          \n",
    "        d=json_normalize(all_articles['articles'])         \n",
    "        newdf=d[[\"url\",\"publishedAt\",\"source.name\",\"author\"]]\n",
    "        dic=newdf.set_index([\"source.name\",\"publishedAt\",\"author\"]) \n",
    "        [\"url\"].to_dict()        \n",
    "        for (k,v) in dic.items():            \n",
    "            page = requests.get(v)            \n",
    "            html = page.content            \n",
    "            soup = BeautifulSoup(html, \"lxml\")            \n",
    "            text = soup.get_text()            \n",
    "            d2=soup.find_all(\"p\")            \n",
    "            newd[k]=re.sub(r'<.+?>',r'',str(d2))     \n",
    "    return newd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping through the zipped version of the from and to lists for the dates, we get a list of all articles for the 30-day timeframe. The reason I chose to loop this is so that I can do analysis for every single day. I then store it in a data frame. I then get the relevant columns and store them back in a dictionary. I want to parse the content in the news URL so that I get the content only from the articles. I used the BeautifulSoup package in Python here to parse the content and get relevant <p> tags where the information resides. Since we are primarily focused on text data here, we need information between these paragraph tags. You can find more information on BeautifulSoup here:\n",
    "    \n",
    "Once we have cleaner data, we can now proceed towards the Wordclouds to analyze a pattern.\n",
    "\n",
    "News Analysis using WordCloud\n",
    "\n",
    "Now, we move on to the Wordcloud. The part where we can make sense of the data from the news. What are some of the commonly occurring patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcld(dictionary):        \n",
    "    newd={}    \n",
    "    for (k,v) in dictionary.items():        \n",
    "    if v!='[]':            \n",
    "        wordcloud = WordCloud().generate(str(dictionary[k]))                \n",
    "        fig, axes= plt.subplots(figsize=(20,12),clear=True)                     \n",
    "        plt.imshow(wordcloud, interpolation='bilinear')            \n",
    "        plt.show()                 \n",
    "    else:            \n",
    "        print(str(k[0])+\"_\"+str(k[1][5:10])+\"_\"+str(k[1][11:13])              \n",
    "        +\"_\"+str(k[1][14:16]) +\"_\"+str(k[1][17:19])+\"_\"+str(k[2]))             \n",
    "        print(\"Wordcloud Not applicable\")\n",
    "dic=func(\"Indian Economy\")\n",
    "wordcld(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 from NewsAPI Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from newsapi import NewsApiClient\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('test1.env')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the News API key enviroment variable\n",
    "api_key = os.getenv(\"news_api\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d6be1ce1f0ed4777a2f0ea79b48d576f'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a newsapi client\n",
    "newsapi = NewsApiClient(api_key=api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<newsapi.newsapi_client.NewsApiClient at 0x1999aa8fcc8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok',\n",
       " 'totalResults': 9,\n",
       " 'articles': [{'source': {'id': None, 'name': 'Science Daily'},\n",
       "   'author': None,\n",
       "   'title': 'Measuring how the Arctic responds to climate change - Science Daily',\n",
       "   'description': 'The Arctic has been warming more than twice as fast as the rest of the planet. Meanwhile CO2 measurements show substantial increases in the amount of carbon absorbed into and emitted by Arctic plants and soil. Scientists assumed this was playing a large role …',\n",
       "   'url': 'https://www.sciencedaily.com/releases/2021/08/210824135336.htm',\n",
       "   'urlToImage': 'https://www.sciencedaily.com/images/scidaily-icon.png',\n",
       "   'publishedAt': '2021-08-24T19:43:28Z',\n",
       "   'content': 'Researchers at the University of East Anglia have helped develop a new way to measure how Arctic plants respond to climate change.Over the past few decades, the Arctic has been warming more than twic… [+6907 chars]'},\n",
       "  {'source': {'id': None, 'name': 'Yahoo Entertainment'},\n",
       "   'author': 'Ronan Glon',\n",
       "   'title': 'Ford Focus ST gets factory-fitted adjustable coil-overs in Europe - Yahoo Singapore News',\n",
       "   'description': 'Ford stopped selling the Focus in the United States as it pivoted towards pickups, SUVs, and crossovers, but the nameplate lives on overseas.  Unveiled in...',\n",
       "   'url': 'https://sg.news.yahoo.com/ford-focus-st-gets-factory-140000011.html',\n",
       "   'urlToImage': 'https://s.yimg.com/uu/api/res/1.2/7XF4yQ7qU_nod24kf9E_vw--~B/aD01OTc7dz0xMDYyO2FwcGlkPXl0YWNoeW9u/https://media.zenfs.com/en/autoblog_50/91181dffbff42d4183fd5606efc2e08f',\n",
       "   'publishedAt': '2021-08-24T14:00:00Z',\n",
       "   'content': 'See Full Image Gallery &gt;&gt;\\r\\nFord stopped selling the Focus in the United States as it pivoted towards pickups, SUVs, and crossovers, but the nameplate lives on overseas. It recently spawned a li… [+1908 chars]'},\n",
       "  {'source': {'id': 'reuters', 'name': 'Reuters'},\n",
       "   'author': 'Nidhi Verma, Brijesh Patel',\n",
       "   'title': \"India's July oil imports hit 1-year low on refinery maintenance - Reuters\",\n",
       "   'description': \"India's July crude oil imports slumped to their lowest in a year, tanker arrival data from industry sources showed, and are likely to rebound in August as refiners are expected to boost runs after maintenance of units.\",\n",
       "   'url': 'https://www.reuters.com/article/india-oil-idUSL4N2PU2UF',\n",
       "   'urlToImage': 'https://s1.reutersmedia.net/resources_v2/images/rcom-default.png?w=800',\n",
       "   'publishedAt': '2021-08-24T13:48:00Z',\n",
       "   'content': 'NEW DELHI, BANGALORE Aug 24 (Reuters) - Indias July crude oil imports slumped to their lowest in a year, tanker arrival data from industry sources showed, and are likely to rebound in August as refin… [+1893 chars]'},\n",
       "  {'source': {'id': 'the-globe-and-mail', 'name': 'The Globe And Mail'},\n",
       "   'author': None,\n",
       "   'title': \"NDP Leader Jagmeet Singh's promise to end oil subsidies not as clear as it sounds - The Globe and Mail\",\n",
       "   'description': 'In a election that is clean cut, the clean cutting of subsidies is not so clear for NDP’s Jagmeet Singh',\n",
       "   'url': 'https://www.theglobeandmail.com/politics/article-ndp-leader-jagmeet-singhs-promise-to-end-oil-subsidies-not-as-clear-as/',\n",
       "   'urlToImage': 'https://www.theglobeandmail.com/resizer/FIEjEokQIxS8HuNeGl38vSzic6o=/1200x0/filters:quality(80)/cloudfront-us-east-1.images.arcpublishing.com/tgam/MVAMYQJHVNI6JFKKJY5VEVDSDI.jpg',\n",
       "   'publishedAt': '2021-08-24T11:30:00Z',\n",
       "   'content': 'New Democratic Party leader Jagmeet Singh greets NDP candidate for Papineau Christine Pare, right, in Montreal on Aug. 23, 2021. The NDP leader visited several constituents and businesses in the Papi… [+4618 chars]'},\n",
       "  {'source': {'id': 'news-com-au', 'name': 'News.com.au'},\n",
       "   'author': 'Nick Bond',\n",
       "   'title': 'Survivor star’s brutal public sledge - NEWS.com.au',\n",
       "   'description': '<p>WARNING: Survivor spoilers below. </p>',\n",
       "   'url': 'https://www.news.com.au/entertainment/tv/reality-tv/australian-survivor/survivor-contestant-georges-brutal-public-sledge/news-story/0a2a05f29ffb98074f209c8e1577cc12',\n",
       "   'urlToImage': 'https://content.api.news/v3/images/bin/1375857d2df1207ea5d85257704c2c63',\n",
       "   'publishedAt': '2021-08-24T11:12:37Z',\n",
       "   'content': 'One Survivor contestant just broke all the rules of tribal council, leaving his tribemates stunned with this savage dig.WARNING: Survivor spoilers below. \\r\\nAustralian Survivor contestant George deliv… [+2274 chars]'},\n",
       "  {'source': {'id': 'financial-post', 'name': 'Financial Post'},\n",
       "   'author': 'Bloomberg News',\n",
       "   'title': 'Chevron, Hess Mandate Covid Vaccines for U.S. Gulf Platforms - Regina Leader-Post',\n",
       "   'description': '(Bloomberg) — Chevron Corp. and Hess Corp. stepped up the oil industry’s attempts to protect workers from Covid-19 by requiring vaccines for employees who work…',\n",
       "   'url': 'https://financialpost.com/pmn/business-pmn/chevron-expands-vaccination-mandate-to-gulf-of-mexico-workers',\n",
       "   'urlToImage': None,\n",
       "   'publishedAt': '2021-08-23T14:44:54Z',\n",
       "   'content': 'Article content\\r\\n(Bloomberg) Chevron Corp. and Hess Corp. stepped up the oil industrys attempts to protect workers from Covid-19 by requiring vaccines for employees who work on platforms in the Gulf … [+1934 chars]'},\n",
       "  {'source': {'id': 'independent', 'name': 'Independent'},\n",
       "   'author': 'Louis Chilton',\n",
       "   'title': 'Iron Man 3 star addresses shock return to Marvel universe in Shang-Chi - Yahoo Singapore News',\n",
       "   'description': '*Mild spoilers follow for ‘Shang-Chi and the Legend of the Ten Rings’*',\n",
       "   'url': 'https://www.independent.co.uk/arts-entertainment/films/news/shang-chi-mandarin-ben-kingsley-b1907236.html',\n",
       "   'urlToImage': 'https://static.independent.co.uk/2021/08/23/15/newFile-10.jpg?width=1200&auto=webp&quality=75',\n",
       "   'publishedAt': '2021-08-23T14:38:45Z',\n",
       "   'content': 'One of the stars of Iron Man 3 has opened up about a return to the MCU in the forthcoming film Shang-Chi and the Legend of the Ten Rings.\\r\\nMild spoilers for Shang-Chi follow...\\r\\nIn 2013s Iron Man 3, … [+1882 chars]'}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch top news articles about oil\n",
    "oil_headlines = newsapi.get_top_headlines(q=\"oil\")\n",
    "oil_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total articles about oil: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'source': {'id': None, 'name': 'Science Daily'},\n",
       "  'author': None,\n",
       "  'title': 'Measuring how the Arctic responds to climate change - Science Daily',\n",
       "  'description': 'The Arctic has been warming more than twice as fast as the rest of the planet. Meanwhile CO2 measurements show substantial increases in the amount of carbon absorbed into and emitted by Arctic plants and soil. Scientists assumed this was playing a large role …',\n",
       "  'url': 'https://www.sciencedaily.com/releases/2021/08/210824135336.htm',\n",
       "  'urlToImage': 'https://www.sciencedaily.com/images/scidaily-icon.png',\n",
       "  'publishedAt': '2021-08-24T19:43:28Z',\n",
       "  'content': 'Researchers at the University of East Anglia have helped develop a new way to measure how Arctic plants respond to climate change.Over the past few decades, the Arctic has been warming more than twic… [+6907 chars]'},\n",
       " {'source': {'id': None, 'name': 'Yahoo Entertainment'},\n",
       "  'author': 'Ronan Glon',\n",
       "  'title': 'Ford Focus ST gets factory-fitted adjustable coil-overs in Europe - Yahoo Singapore News',\n",
       "  'description': 'Ford stopped selling the Focus in the United States as it pivoted towards pickups, SUVs, and crossovers, but the nameplate lives on overseas.  Unveiled in...',\n",
       "  'url': 'https://sg.news.yahoo.com/ford-focus-st-gets-factory-140000011.html',\n",
       "  'urlToImage': 'https://s.yimg.com/uu/api/res/1.2/7XF4yQ7qU_nod24kf9E_vw--~B/aD01OTc7dz0xMDYyO2FwcGlkPXl0YWNoeW9u/https://media.zenfs.com/en/autoblog_50/91181dffbff42d4183fd5606efc2e08f',\n",
       "  'publishedAt': '2021-08-24T14:00:00Z',\n",
       "  'content': 'See Full Image Gallery &gt;&gt;\\r\\nFord stopped selling the Focus in the United States as it pivoted towards pickups, SUVs, and crossovers, but the nameplate lives on overseas. It recently spawned a li… [+1908 chars]'},\n",
       " {'source': {'id': 'reuters', 'name': 'Reuters'},\n",
       "  'author': 'Nidhi Verma, Brijesh Patel',\n",
       "  'title': \"India's July oil imports hit 1-year low on refinery maintenance - Reuters\",\n",
       "  'description': \"India's July crude oil imports slumped to their lowest in a year, tanker arrival data from industry sources showed, and are likely to rebound in August as refiners are expected to boost runs after maintenance of units.\",\n",
       "  'url': 'https://www.reuters.com/article/india-oil-idUSL4N2PU2UF',\n",
       "  'urlToImage': 'https://s1.reutersmedia.net/resources_v2/images/rcom-default.png?w=800',\n",
       "  'publishedAt': '2021-08-24T13:48:00Z',\n",
       "  'content': 'NEW DELHI, BANGALORE Aug 24 (Reuters) - Indias July crude oil imports slumped to their lowest in a year, tanker arrival data from industry sources showed, and are likely to rebound in August as refin… [+1893 chars]'},\n",
       " {'source': {'id': 'the-globe-and-mail', 'name': 'The Globe And Mail'},\n",
       "  'author': None,\n",
       "  'title': \"NDP Leader Jagmeet Singh's promise to end oil subsidies not as clear as it sounds - The Globe and Mail\",\n",
       "  'description': 'In a election that is clean cut, the clean cutting of subsidies is not so clear for NDP’s Jagmeet Singh',\n",
       "  'url': 'https://www.theglobeandmail.com/politics/article-ndp-leader-jagmeet-singhs-promise-to-end-oil-subsidies-not-as-clear-as/',\n",
       "  'urlToImage': 'https://www.theglobeandmail.com/resizer/FIEjEokQIxS8HuNeGl38vSzic6o=/1200x0/filters:quality(80)/cloudfront-us-east-1.images.arcpublishing.com/tgam/MVAMYQJHVNI6JFKKJY5VEVDSDI.jpg',\n",
       "  'publishedAt': '2021-08-24T11:30:00Z',\n",
       "  'content': 'New Democratic Party leader Jagmeet Singh greets NDP candidate for Papineau Christine Pare, right, in Montreal on Aug. 23, 2021. The NDP leader visited several constituents and businesses in the Papi… [+4618 chars]'},\n",
       " {'source': {'id': 'news-com-au', 'name': 'News.com.au'},\n",
       "  'author': 'Nick Bond',\n",
       "  'title': 'Survivor star’s brutal public sledge - NEWS.com.au',\n",
       "  'description': '<p>WARNING: Survivor spoilers below. </p>',\n",
       "  'url': 'https://www.news.com.au/entertainment/tv/reality-tv/australian-survivor/survivor-contestant-georges-brutal-public-sledge/news-story/0a2a05f29ffb98074f209c8e1577cc12',\n",
       "  'urlToImage': 'https://content.api.news/v3/images/bin/1375857d2df1207ea5d85257704c2c63',\n",
       "  'publishedAt': '2021-08-24T11:12:37Z',\n",
       "  'content': 'One Survivor contestant just broke all the rules of tribal council, leaving his tribemates stunned with this savage dig.WARNING: Survivor spoilers below. \\r\\nAustralian Survivor contestant George deliv… [+2274 chars]'},\n",
       " {'source': {'id': 'financial-post', 'name': 'Financial Post'},\n",
       "  'author': 'Bloomberg News',\n",
       "  'title': 'Chevron, Hess Mandate Covid Vaccines for U.S. Gulf Platforms - Regina Leader-Post',\n",
       "  'description': '(Bloomberg) — Chevron Corp. and Hess Corp. stepped up the oil industry’s attempts to protect workers from Covid-19 by requiring vaccines for employees who work…',\n",
       "  'url': 'https://financialpost.com/pmn/business-pmn/chevron-expands-vaccination-mandate-to-gulf-of-mexico-workers',\n",
       "  'urlToImage': None,\n",
       "  'publishedAt': '2021-08-23T14:44:54Z',\n",
       "  'content': 'Article content\\r\\n(Bloomberg) Chevron Corp. and Hess Corp. stepped up the oil industrys attempts to protect workers from Covid-19 by requiring vaccines for employees who work on platforms in the Gulf … [+1934 chars]'},\n",
       " {'source': {'id': 'independent', 'name': 'Independent'},\n",
       "  'author': 'Louis Chilton',\n",
       "  'title': 'Iron Man 3 star addresses shock return to Marvel universe in Shang-Chi - Yahoo Singapore News',\n",
       "  'description': '*Mild spoilers follow for ‘Shang-Chi and the Legend of the Ten Rings’*',\n",
       "  'url': 'https://www.independent.co.uk/arts-entertainment/films/news/shang-chi-mandarin-ben-kingsley-b1907236.html',\n",
       "  'urlToImage': 'https://static.independent.co.uk/2021/08/23/15/newFile-10.jpg?width=1200&auto=webp&quality=75',\n",
       "  'publishedAt': '2021-08-23T14:38:45Z',\n",
       "  'content': 'One of the stars of Iron Man 3 has opened up about a return to the MCU in the forthcoming film Shang-Chi and the Legend of the Ten Rings.\\r\\nMild spoilers for Shang-Chi follow...\\r\\nIn 2013s Iron Man 3, … [+1882 chars]'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print total articles\n",
    "print(f\"Total articles about oil: {oil_headlines['totalResults']}\")\n",
    "\n",
    "# Show sample article\n",
    "oil_headlines[\"articles\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>urlToImage</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'id': None, 'name': 'Science Daily'}</td>\n",
       "      <td>None</td>\n",
       "      <td>Measuring how the Arctic responds to climate c...</td>\n",
       "      <td>The Arctic has been warming more than twice as...</td>\n",
       "      <td>https://www.sciencedaily.com/releases/2021/08/...</td>\n",
       "      <td>https://www.sciencedaily.com/images/scidaily-i...</td>\n",
       "      <td>2021-08-24T19:43:28Z</td>\n",
       "      <td>Researchers at the University of East Anglia h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'id': None, 'name': 'Yahoo Entertainment'}</td>\n",
       "      <td>Ronan Glon</td>\n",
       "      <td>Ford Focus ST gets factory-fitted adjustable c...</td>\n",
       "      <td>Ford stopped selling the Focus in the United S...</td>\n",
       "      <td>https://sg.news.yahoo.com/ford-focus-st-gets-f...</td>\n",
       "      <td>https://s.yimg.com/uu/api/res/1.2/7XF4yQ7qU_no...</td>\n",
       "      <td>2021-08-24T14:00:00Z</td>\n",
       "      <td>See Full Image Gallery &amp;gt;&amp;gt;\\r\\nFord stoppe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'id': 'reuters', 'name': 'Reuters'}</td>\n",
       "      <td>Nidhi Verma, Brijesh Patel</td>\n",
       "      <td>India's July oil imports hit 1-year low on ref...</td>\n",
       "      <td>India's July crude oil imports slumped to thei...</td>\n",
       "      <td>https://www.reuters.com/article/india-oil-idUS...</td>\n",
       "      <td>https://s1.reutersmedia.net/resources_v2/image...</td>\n",
       "      <td>2021-08-24T13:48:00Z</td>\n",
       "      <td>NEW DELHI, BANGALORE Aug 24 (Reuters) - Indias...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'id': 'the-globe-and-mail', 'name': 'The Glob...</td>\n",
       "      <td>None</td>\n",
       "      <td>NDP Leader Jagmeet Singh's promise to end oil ...</td>\n",
       "      <td>In a election that is clean cut, the clean cut...</td>\n",
       "      <td>https://www.theglobeandmail.com/politics/artic...</td>\n",
       "      <td>https://www.theglobeandmail.com/resizer/FIEjEo...</td>\n",
       "      <td>2021-08-24T11:30:00Z</td>\n",
       "      <td>New Democratic Party leader Jagmeet Singh gree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'id': 'news-com-au', 'name': 'News.com.au'}</td>\n",
       "      <td>Nick Bond</td>\n",
       "      <td>Survivor star’s brutal public sledge - NEWS.co...</td>\n",
       "      <td>&lt;p&gt;WARNING: Survivor spoilers below. &lt;/p&gt;</td>\n",
       "      <td>https://www.news.com.au/entertainment/tv/reali...</td>\n",
       "      <td>https://content.api.news/v3/images/bin/1375857...</td>\n",
       "      <td>2021-08-24T11:12:37Z</td>\n",
       "      <td>One Survivor contestant just broke all the rul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0              {'id': None, 'name': 'Science Daily'}   \n",
       "1        {'id': None, 'name': 'Yahoo Entertainment'}   \n",
       "2               {'id': 'reuters', 'name': 'Reuters'}   \n",
       "3  {'id': 'the-globe-and-mail', 'name': 'The Glob...   \n",
       "4       {'id': 'news-com-au', 'name': 'News.com.au'}   \n",
       "\n",
       "                       author  \\\n",
       "0                        None   \n",
       "1                  Ronan Glon   \n",
       "2  Nidhi Verma, Brijesh Patel   \n",
       "3                        None   \n",
       "4                   Nick Bond   \n",
       "\n",
       "                                               title  \\\n",
       "0  Measuring how the Arctic responds to climate c...   \n",
       "1  Ford Focus ST gets factory-fitted adjustable c...   \n",
       "2  India's July oil imports hit 1-year low on ref...   \n",
       "3  NDP Leader Jagmeet Singh's promise to end oil ...   \n",
       "4  Survivor star’s brutal public sledge - NEWS.co...   \n",
       "\n",
       "                                         description  \\\n",
       "0  The Arctic has been warming more than twice as...   \n",
       "1  Ford stopped selling the Focus in the United S...   \n",
       "2  India's July crude oil imports slumped to thei...   \n",
       "3  In a election that is clean cut, the clean cut...   \n",
       "4          <p>WARNING: Survivor spoilers below. </p>   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.sciencedaily.com/releases/2021/08/...   \n",
       "1  https://sg.news.yahoo.com/ford-focus-st-gets-f...   \n",
       "2  https://www.reuters.com/article/india-oil-idUS...   \n",
       "3  https://www.theglobeandmail.com/politics/artic...   \n",
       "4  https://www.news.com.au/entertainment/tv/reali...   \n",
       "\n",
       "                                          urlToImage           publishedAt  \\\n",
       "0  https://www.sciencedaily.com/images/scidaily-i...  2021-08-24T19:43:28Z   \n",
       "1  https://s.yimg.com/uu/api/res/1.2/7XF4yQ7qU_no...  2021-08-24T14:00:00Z   \n",
       "2  https://s1.reutersmedia.net/resources_v2/image...  2021-08-24T13:48:00Z   \n",
       "3  https://www.theglobeandmail.com/resizer/FIEjEo...  2021-08-24T11:30:00Z   \n",
       "4  https://content.api.news/v3/images/bin/1375857...  2021-08-24T11:12:37Z   \n",
       "\n",
       "                                             content  \n",
       "0  Researchers at the University of East Anglia h...  \n",
       "1  See Full Image Gallery &gt;&gt;\\r\\nFord stoppe...  \n",
       "2  NEW DELHI, BANGALORE Aug 24 (Reuters) - Indias...  \n",
       "3  New Democratic Party leader Jagmeet Singh gree...  \n",
       "4  One Survivor contestant just broke all the rul...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the response dictionary to a DataFrame\n",
    "oil_df = pd.DataFrame.from_dict(oil_headlines[\"articles\"])\n",
    "\n",
    "oil_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " all_articles = newsapi.get_everything(q=query,language='en',\n",
    "        sort_by='relevancy',from_param=from_dt,to=to_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    " all_articles = newsapi.get_everything(q=\"google\",language='en',\n",
    "        sort_by='relevancy',from_param=\"2021-07-24\",to=\"2021-70-30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': {'id': 'the-verge', 'name': 'The Verge'},\n",
       " 'author': 'Jon Porter',\n",
       " 'title': 'Google is shutting down its Android Auto mobile app in favor of Google Assistant',\n",
       " 'description': 'Google has confirmed that it’s shutting down the standalone “Android Auto for Phone Screens” app with Android 12. It launched in 2019 as a stopgap measure ahead of Google Assistant’s driving mode.',\n",
       " 'url': 'https://www.theverge.com/2021/8/20/22633755/google-android-auto-for-phone-screens-shutting-down-android-12-google-assistant-driving-mode',\n",
       " 'urlToImage': 'https://cdn.vox-cdn.com/thumbor/RqOS4nKvRSt2fVr7eK9XOCW0QJY=/0x146:2040x1214/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/10646769/acastro_180413_1777_android_0001.jpg',\n",
       " 'publishedAt': '2021-08-20T10:15:12Z',\n",
       " 'content': 'Android 12 will mark the end of the stopgap app\\r\\nIllustration by Alex Castro / The Verge\\r\\nGoogle has confirmed its shutting down the standalone Android Auto for Phone Screens app with Android 12. Ins… [+2043 chars]'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_articles['articles'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-08-20'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_articles['articles'][0]['publishedAt'][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 fuction to loop through articles and sort description by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2021-08-20\n",
       "1     2021-07-28\n",
       "2     2021-07-30\n",
       "3     2021-08-08\n",
       "4     2021-08-11\n",
       "5     2021-08-16\n",
       "6     2021-07-27\n",
       "7     2021-08-17\n",
       "8     2021-08-03\n",
       "9     2021-08-12\n",
       "10    2021-08-17\n",
       "11    2021-08-17\n",
       "12    2021-08-03\n",
       "13    2021-08-19\n",
       "14    2021-08-07\n",
       "15    2021-07-29\n",
       "16    2021-08-05\n",
       "17    2021-08-18\n",
       "18    2021-08-09\n",
       "19    2021-07-31\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ddelete\n",
    "# art_df = pd.DataFrame.from_dict(all_articles['articles'])\n",
    "art_df.head(2)\n",
    "art_df['date'] = art_df['publishedAt'].apply (lambda x: x[:10])\n",
    "art_df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_news (in_news):\n",
    "    '''\n",
    "    loop through artiles in news api and sort by date.\n",
    "    create data frame \n",
    "    one dataframe with full content\n",
    "    second with text and date only\n",
    "    '''\n",
    "    #convert articles to dataframe\n",
    "    art_df = pd.DataFrame.from_dict(all_articles['articles'])\n",
    "    #change to a date string\n",
    "#     df['age']=df.apply(lambda x: x['age']+3,axis=1)\n",
    "    # create a column text that concats title descripiton and content\n",
    "    art_df ['text'] = art_df['title'] + \" \" + art_df['description'] + \" \" + art_df['content']\n",
    "    art_df['date'] = art_df['publishedAt'].apply (lambda x: x[:10])\n",
    "    #sort by date\n",
    "    art_df.sort_values (by=['date'], inplace = True)\n",
    "    #concat all text by date\n",
    "    text_df = art_df.groupby('date')['text'].apply (lambda x: ','.join (x)).reset_index()\n",
    "    return art_df, text_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>Google TV mobile app redesign adds new service...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-28</td>\n",
       "      <td>Google will require coronavirus vaccines for r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-29</td>\n",
       "      <td>Google Is Booting 'Sugar Daddy' Apps From the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-30</td>\n",
       "      <td>Pittsburgh Google contractors ratify deal with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>Apple pulls anti-vax social app over misinform...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text\n",
       "0  2021-07-27  Google TV mobile app redesign adds new service...\n",
       "1  2021-07-28  Google will require coronavirus vaccines for r...\n",
       "2  2021-07-29  Google Is Booting 'Sugar Daddy' Apps From the ...\n",
       "3  2021-07-30  Pittsburgh Google contractors ratify deal with...\n",
       "4  2021-07-31  Apple pulls anti-vax social app over misinform..."
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art_df, text_df = sort_news(all_articles)\n",
    "text_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Google TV mobile app redesign adds new services and recommendations Following last fall’s debut of Google TV, the new user interface for Chromecast devices, Google is today giving its Google TV companion app for Android a makeover. The updated version of the mobile app for Google TV includes an updated user interface, expande… Following last fall’s debut of Google TV, the new user interface for Chromecast devices, Google is today giving its Google TV companion app for Android a makeover. The updated version of the mobile a… [+3311 chars]'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-07-27</th>\n",
       "      <td>Google TV mobile app redesign adds new service...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-28</th>\n",
       "      <td>Google will require coronavirus vaccines for r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-29</th>\n",
       "      <td>Google Is Booting 'Sugar Daddy' Apps From the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-30</th>\n",
       "      <td>Pittsburgh Google contractors ratify deal with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-31</th>\n",
       "      <td>Apple pulls anti-vax social app over misinform...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         text\n",
       "date                                                         \n",
       "2021-07-27  Google TV mobile app redesign adds new service...\n",
       "2021-07-28  Google will require coronavirus vaccines for r...\n",
       "2021-07-29  Google Is Booting 'Sugar Daddy' Apps From the ...\n",
       "2021-07-30  Pittsburgh Google contractors ratify deal with...\n",
       "2021-07-31  Apple pulls anti-vax social app over misinform..."
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = text_df.copy()\n",
    "test_text.set_index('date', drop = True, inplace = True)\n",
    "test_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-07-27</th>\n",
       "      <td>Google TV mobile app redesign adds new service...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-28</th>\n",
       "      <td>Google will require coronavirus vaccines for r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-29</th>\n",
       "      <td>Google Is Booting 'Sugar Daddy' Apps From the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-30</th>\n",
       "      <td>Pittsburgh Google contractors ratify deal with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-31</th>\n",
       "      <td>Apple pulls anti-vax social app over misinform...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         text\n",
       "date                                                         \n",
       "2021-07-27  Google TV mobile app redesign adds new service...\n",
       "2021-07-28  Google will require coronavirus vaccines for r...\n",
       "2021-07-29  Google Is Booting 'Sugar Daddy' Apps From the ...\n",
       "2021-07-30  Pittsburgh Google contractors ratify deal with...\n",
       "2021-07-31  Apple pulls anti-vax social app over misinform..."
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = text_df.copy()\n",
    "test_text.set_index('date', drop = True, inplace = True)\n",
    "test_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 combine data with news\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_index_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hassan\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>-0.016659</td>\n",
       "      <td>-0.050769</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>-0.010703</td>\n",
       "      <td>-0.010099</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>0.002953</td>\n",
       "      <td>-0.012007</td>\n",
       "      <td>-0.016820</td>\n",
       "      <td>0.008038</td>\n",
       "      <td>0.008199</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>0.003650</td>\n",
       "      <td>-0.003667</td>\n",
       "      <td>-0.011996</td>\n",
       "      <td>-0.005050</td>\n",
       "      <td>-0.005946</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>0.009591</td>\n",
       "      <td>0.022522</td>\n",
       "      <td>-0.011685</td>\n",
       "      <td>0.016229</td>\n",
       "      <td>0.007287</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A       AAL       AAP      AAPL      ABBV text\n",
       "2020-01-02       NaN       NaN       NaN       NaN       NaN  NaN\n",
       "2020-01-03 -0.016659 -0.050769  0.000502 -0.010703 -0.010099  NaN\n",
       "2020-01-06  0.002953 -0.012007 -0.016820  0.008038  0.008199  NaN\n",
       "2020-01-07  0.003650 -0.003667 -0.011996 -0.005050 -0.005946  NaN\n",
       "2020-01-08  0.009591  0.022522 -0.011685  0.016229  0.007287  NaN"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_price = pd.concat([date_index_df, test_text], axis = 1, join = \"outer\")\n",
    "news_price.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Get sentiment. from IBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "import json\n",
    "# deoes not work use next cell\n",
    "# from pandas import json_normalize\n",
    "from ibm_watson import ToneAnalyzerV3\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from pandas.io.json import json_normalize\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "load_dotenv('ibm-credentials.env')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Tone Analyzer API Key and URL\n",
    "tone_api = os.getenv(\"TONE_ANALYZER_APIKEY\")\n",
    "tone_url = os.getenv(\"TONE_ANALYZER_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete\n",
    "# tone_api\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_ibm():\n",
    "    '''\n",
    "    code to initialize IBM netork\n",
    "    '''\n",
    "    #load environment\n",
    "    load_dotenv('ibm-credentials.env')\n",
    "    # Initialize Tone Analyser Client\n",
    "\n",
    "    # Create authentication object\n",
    "    authenticator = IAMAuthenticator(tone_api)\n",
    "\n",
    "    # Create tone_analyzer instance\n",
    "    tone_analyzer = ToneAnalyzerV3(\n",
    "        version=\"2017-09-21\",\n",
    "        authenticator=authenticator                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
    "    )\n",
    "\n",
    "    # Set the service endpoint\n",
    "    tone_analyzer.set_service_url(tone_url)\n",
    "    return tone_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tone_series(in_text):\n",
    "    '''\n",
    "    Takes a text and generates a series of tones based on tonlist\n",
    "    need to make sure IBM network is alived\n",
    "    in_text = text to be analzye\n",
    "    in_tn = tone analyzer\n",
    "    \n",
    "    '''\n",
    "    #set error variabes\n",
    "    sent_tone = False\n",
    "    doc_tone = False\n",
    "    \n",
    "    #analzye the doe\n",
    "    tone_analysis = tone_analyzer.tone(\n",
    "        {\"text\": in_text},\n",
    "        content_type=\"application/json\",\n",
    "        content_language=\"en\",\n",
    "        accept_language=\"en\",\n",
    "    ).get_result()\n",
    "    \n",
    "    # debug\n",
    "    # debug print(json.dumps(tone_analysis, indent=2))\n",
    "    \n",
    "    #create sentence tone df\n",
    "    # check if there is a sensettone, then put \n",
    "    try:\n",
    "        sentences_tone_df = json_normalize(\n",
    "            data=tone_analysis[\"sentences_tone\"],\n",
    "            record_path=[\"tones\"],\n",
    "            meta=[\"sentence_id\", \"text\"],\n",
    "            )\n",
    "        sent_tone = True\n",
    "    except:\n",
    "        set_tone = False\n",
    "    \n",
    "    #change it to a dataframe\n",
    "    try:\n",
    "        doc_tone_df = json_normalize(data=tone_analysis[\"document_tone\"], record_path=[\"tones\"])\n",
    "        doc_tone = True\n",
    "    except:\n",
    "        doc_tone = False\n",
    "        \n",
    "    \n",
    "    #creae summary fo all tones\n",
    "    # debug print (f'sent_done: {sent_tone}\\n')\n",
    "    # debug print (f'doc_tone: {doc_tone}\\n')\n",
    "    if sent_tone:\n",
    "        tsp_df = sentences_tone_df.groupby('tone_id').sum().transpose()\n",
    "    elif doc_tone:\n",
    "        tsp_df = doc_tone_df.groupby('tone_id').sum().transpose()\n",
    "    else:\n",
    "        return 'error'\n",
    "\n",
    "    #define list of tones\n",
    "    tone_list = ['excited', 'frustrated','impolite', 'polite', 'sad', 'satisfied', 'sympathetic', \n",
    "             'anger', 'disgust', 'fear', 'joy', 'sadness',\n",
    "            'analytical', 'confident', 'tentative',\n",
    "            'openness_big5', 'conscientiousness_big5', 'extraversion_big5', 'agreeableness_big5',  'emotional_range_big5']\n",
    "    \n",
    "    #create tone df with all zeros\n",
    "    zero_df = pd.DataFrame(0, index=np.arange(1), columns=tone_list)\n",
    "    #replace falues from tone_df\n",
    "    zero_df [tsp_df.columns] = tsp_df[tsp_df.columns].values\n",
    "       \n",
    "    # debug print (f'zero_df[0]: {zero_df.iloc[0]}\\n')  \n",
    "\n",
    "    return zero_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Tone Analyser Client\n",
    "\n",
    "# Create authentication object\n",
    "authenticator = IAMAuthenticator(tone_api)\n",
    "\n",
    "# Create tone_analyzer instance\n",
    "tone_analyzer = ToneAnalyzerV3(\n",
    "    version=\"2017-09-21\",\n",
    "    authenticator=authenticator                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
    ")\n",
    "\n",
    "# Set the service endpoint\n",
    "tone_analyzer.set_service_url(tone_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"document_tone\": {\n",
      "    \"tones\": [\n",
      "      {\n",
      "        \"score\": 0.6165,\n",
      "        \"tone_id\": \"sadness\",\n",
      "        \"tone_name\": \"Sadness\"\n",
      "      },\n",
      "      {\n",
      "        \"score\": 0.829888,\n",
      "        \"tone_id\": \"analytical\",\n",
      "        \"tone_name\": \"Analytical\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"sentences_tone\": [\n",
      "    {\n",
      "      \"sentence_id\": 0,\n",
      "      \"text\": \"Team, I know that times are tough!\",\n",
      "      \"tones\": [\n",
      "        {\n",
      "          \"score\": 0.801827,\n",
      "          \"tone_id\": \"analytical\",\n",
      "          \"tone_name\": \"Analytical\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"sentence_id\": 1,\n",
      "      \"text\": \"Product sales have been disappointing for the past three quarters.\",\n",
      "      \"tones\": [\n",
      "        {\n",
      "          \"score\": 0.771241,\n",
      "          \"tone_id\": \"sadness\",\n",
      "          \"tone_name\": \"Sadness\"\n",
      "        },\n",
      "        {\n",
      "          \"score\": 0.687768,\n",
      "          \"tone_id\": \"analytical\",\n",
      "          \"tone_name\": \"Analytical\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"sentence_id\": 2,\n",
      "      \"text\": \"We have a competitive product, but we need to do a better job of selling it!\",\n",
      "      \"tones\": [\n",
      "        {\n",
      "          \"score\": 0.506763,\n",
      "          \"tone_id\": \"analytical\",\n",
      "          \"tone_name\": \"Analytical\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Define text to analyze\n",
    "# test \n",
    "text = \"\"\"\n",
    "Team, I know that times are tough! \n",
    "Product sales have been disappointing for the past three quarters. \n",
    "We have a competitive product, but we need to do a better job of selling it!\n",
    "\"\"\"\n",
    "# text = \"\"\"Team, I know that times are tough!\"\"\"\n",
    "\n",
    "# Analyze the text's tone with the 'tone()' method.\n",
    "tone_analysis = tone_analyzer.tone(\n",
    "    {\"text\": text},\n",
    "    content_type=\"application/json\",\n",
    "    content_language=\"en\",\n",
    "    accept_language=\"en\",\n",
    ").get_result()\n",
    "\n",
    "# Display tone analysis results\n",
    "print(json.dumps(tone_analysis, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>tone_id</th>\n",
       "      <th>tone_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.616500</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.829888</td>\n",
       "      <td>analytical</td>\n",
       "      <td>Analytical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score     tone_id   tone_name\n",
       "0  0.616500     sadness     Sadness\n",
       "1  0.829888  analytical  Analytical"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document Tones\n",
    "doc_tone_df = json_normalize(data=tone_analysis[\"document_tone\"], record_path=[\"tones\"])\n",
    "doc_tone_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>tone_id</th>\n",
       "      <th>tone_name</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.801827</td>\n",
       "      <td>analytical</td>\n",
       "      <td>Analytical</td>\n",
       "      <td>0</td>\n",
       "      <td>Team, I know that times are tough!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.771241</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>1</td>\n",
       "      <td>Product sales have been disappointing for the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.687768</td>\n",
       "      <td>analytical</td>\n",
       "      <td>Analytical</td>\n",
       "      <td>1</td>\n",
       "      <td>Product sales have been disappointing for the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.506763</td>\n",
       "      <td>analytical</td>\n",
       "      <td>Analytical</td>\n",
       "      <td>2</td>\n",
       "      <td>We have a competitive product, but we need to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score     tone_id   tone_name sentence_id  \\\n",
       "0  0.801827  analytical  Analytical           0   \n",
       "1  0.771241     sadness     Sadness           1   \n",
       "2  0.687768  analytical  Analytical           1   \n",
       "3  0.506763  analytical  Analytical           2   \n",
       "\n",
       "                                                text  \n",
       "0                 Team, I know that times are tough!  \n",
       "1  Product sales have been disappointing for the ...  \n",
       "2  Product sales have been disappointing for the ...  \n",
       "3  We have a competitive product, but we need to ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentences Tones\n",
    "sentences_tone_df = json_normalize(\n",
    "    data=tone_analysis[\"sentences_tone\"],\n",
    "    record_path=[\"tones\"],\n",
    "    meta=[\"sentence_id\", \"text\"],\n",
    ")\n",
    "sentences_tone_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = sentences_tone_df.copy()\n",
    "\n",
    "tone_list = ['excited', 'frustrated','impolite', 'polite', 'sad', 'satisfied', 'sympathetic', \n",
    "             'anger', 'disgust', 'fear', 'joy', 'sadness',\n",
    "            'analytical', 'confident', 'tentative',\n",
    "            'openness_big5', 'conscientiousness_big5', 'extraversion_big5', 'agreeableness_big5',  'emotional_range_big5']\n",
    "tone_analyzer = init_ibm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>tone_id</th>\n",
       "      <th>tone_name</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>text</th>\n",
       "      <th>excited</th>\n",
       "      <th>frustrated</th>\n",
       "      <th>impolite</th>\n",
       "      <th>polite</th>\n",
       "      <th>sad</th>\n",
       "      <th>...</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>analytical</th>\n",
       "      <th>confident</th>\n",
       "      <th>tentative</th>\n",
       "      <th>openness_big5</th>\n",
       "      <th>conscientiousness_big5</th>\n",
       "      <th>extraversion_big5</th>\n",
       "      <th>agreeableness_big5</th>\n",
       "      <th>emotional_range_big5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.801827</td>\n",
       "      <td>analytical</td>\n",
       "      <td>Analytical</td>\n",
       "      <td>0</td>\n",
       "      <td>Team, I know that times are tough!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.801827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.771241</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>1</td>\n",
       "      <td>Product sales have been disappointing for the ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.771241</td>\n",
       "      <td>0.687768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.687768</td>\n",
       "      <td>analytical</td>\n",
       "      <td>Analytical</td>\n",
       "      <td>1</td>\n",
       "      <td>Product sales have been disappointing for the ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.771241</td>\n",
       "      <td>0.687768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.506763</td>\n",
       "      <td>analytical</td>\n",
       "      <td>Analytical</td>\n",
       "      <td>2</td>\n",
       "      <td>We have a competitive product, but we need to ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.506763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      score     tone_id   tone_name sentence_id  \\\n",
       "0  0.801827  analytical  Analytical           0   \n",
       "1  0.771241     sadness     Sadness           1   \n",
       "2  0.687768  analytical  Analytical           1   \n",
       "3  0.506763  analytical  Analytical           2   \n",
       "\n",
       "                                                text  excited  frustrated  \\\n",
       "0                 Team, I know that times are tough!      0.0         0.0   \n",
       "1  Product sales have been disappointing for the ...      0.0         0.0   \n",
       "2  Product sales have been disappointing for the ...      0.0         0.0   \n",
       "3  We have a competitive product, but we need to ...      0.0         0.0   \n",
       "\n",
       "   impolite  polite  sad  ...  joy   sadness  analytical  confident  \\\n",
       "0       0.0     0.0  0.0  ...  0.0  0.000000    0.801827        0.0   \n",
       "1       0.0     0.0  0.0  ...  0.0  0.771241    0.687768        0.0   \n",
       "2       0.0     0.0  0.0  ...  0.0  0.771241    0.687768        0.0   \n",
       "3       0.0     0.0  0.0  ...  0.0  0.000000    0.506763        0.0   \n",
       "\n",
       "   tentative  openness_big5  conscientiousness_big5  extraversion_big5  \\\n",
       "0        0.0            0.0                     0.0                0.0   \n",
       "1        0.0            0.0                     0.0                0.0   \n",
       "2        0.0            0.0                     0.0                0.0   \n",
       "3        0.0            0.0                     0.0                0.0   \n",
       "\n",
       "   agreeableness_big5  emotional_range_big5  \n",
       "0                 0.0                   0.0  \n",
       "1                 0.0                   0.0  \n",
       "2                 0.0                   0.0  \n",
       "3                 0.0                   0.0  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = sentences_tone_df.copy()\n",
    "# test_df[tone_list] = test_df['text'].apply(create_tone_series)\n",
    "# appiled_df = df.apply(lambda row: fn(row.text), axis='columns', result_type='expand') \n",
    "test_df[tone_list] = test_df['text'].apply(lambda x: create_tone_series(x))\n",
    "# # df.merge(df.textcol.apply(lambda s: pd.Series({'feature1':s+1, 'feature2':s-1})), \n",
    "#     left_index=True, right_index=True)\n",
    "# test_df.merge(test_df.textcol.apply(lambda s:create_tone_series(x)), left_index=True, right_index=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_dotenv('ibm-credentials.env')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
